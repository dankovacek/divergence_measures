{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0bd3e2d-4130-4fd8-8d0e-aebdadd4d447",
   "metadata": {},
   "source": [
    "# Predictability of Kullback-Leibler (KL) Divergence\n",
    "\n",
    "In the first step, we looked at the predictability of an information measure computed on individual distributions.  If the measure could be predicted from attributes, then the uncertainty of unmonitored locations could be estimated.  Here we make a comparison of runoff between two locations and ask if the **Kullback-Leibler Divergence** (KLD) of the distribution of unit area runoff between two locations can be predicted from the attributes of both catchments (and their differences). We will again use the gradient boosted decision tree method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9864ab-af00-457b-bfe0-2e69ac18b2d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fdc7bcd-88cd-45b1-8c47-3a3b0a204046",
   "metadata": {},
   "source": [
    "## Citations\n",
    "\n",
    "```{bibliography}\n",
    ":filter: docname in docnames\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}