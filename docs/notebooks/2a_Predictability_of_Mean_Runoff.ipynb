{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5102c59-e6d1-40c9-8fba-3503a7b34cfa",
   "metadata": {},
   "source": [
    "# Predictability of Mean Runoff\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In the data preprocessing, we computed the entropy of the distribution of each individual streamflow time series in bits per sample.  We'll now use an ensemble decision tree method called gradient boosting using the XGBoost (eXtreme Gradient Boosted decision tree) {cite}`chen2016xgboost` library to see if runoff can be predicted from catchment attributes as was shown in {cite}`addor2018ranking`.  The model input features are added in successive model tests to compare the contribution of catchment attribute groups related to climate, terrain, land cover, and soil.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56f760d-4fe7-4a86-bfc4-a9fa56018c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.palettes import Sunset10, Vibrant7\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import (\n",
    "    root_mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    ")\n",
    "\n",
    "import data_processing_functions as dpf\n",
    "\n",
    "from scipy.stats import linregress\n",
    "output_notebook()\n",
    "\n",
    "BASE_DIR = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8a99f5-1e80-4412-9d09-baaa5d80ca82",
   "metadata": {},
   "source": [
    "## Load Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de943461-f460-47b6-8c5b-16f45e07356f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the catchment characteristics\n",
    "attributes_filename = 'BCUB_watershed_attributes_updated.csv'\n",
    "df = pd.read_csv(os.path.join('data', attributes_filename))\n",
    "df.columns = [c.lower() for c in df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fffae6f-1577-4ce3-aa5d-427a3ff80106",
   "metadata": {},
   "source": [
    "Compute the mean runoff for each streamflow timeseries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bde1fc-5d7e-4a8e-b48c-149c036155d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'mean_runoff' not in df.columns:\n",
    "    for i, row in df.iterrows():\n",
    "        mean_runoff = dpf.compute_mean_runoff(row)\n",
    "        df.loc[i, 'mean_runoff'] = mean_runoff\n",
    "    df.to_csv(os.path.join(BASE_DIR, 'data', attributes_filename), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3f8dcc-d438-474c-876d-77deb64a2b8f",
   "metadata": {},
   "source": [
    "Subdivide the attributes into related classes: terrain, land cover, soil, climate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86bb960-99c4-48b2-832a-0b3f233d0c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all the attributes in the input dataframe\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34ccf39-9504-4f26-a1b1-7286a7bf80ef",
   "metadata": {},
   "source": [
    "## Define attribute groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407c1113-81ed-4428-a448-8b7f2bd771c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "terrain = ['drainage_area_km2', 'elevation_m', 'slope_deg', 'aspect_deg']\n",
    "land_cover = [\n",
    "    'land_use_forest_frac_2010', 'land_use_grass_frac_2010', 'land_use_wetland_frac_2010', 'land_use_water_frac_2010', \n",
    "    'land_use_urban_frac_2010', 'land_use_shrubs_frac_2010', 'land_use_crops_frac_2010', 'land_use_snow_ice_frac_2010']\n",
    "climate = ['prcp', 'srad', 'swe', 'tmax', 'tmin', 'vp', 'high_prcp_freq', 'high_prcp_duration', 'low_prcp_freq', 'low_prcp_duration']\n",
    "soil = ['logk_ice_x100', 'porosity_x100']\n",
    "all_attributes = terrain + land_cover + soil + climate\n",
    "len(all_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7321ee8e-f013-46a3-9978-f37e686040b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len([c for c in all_attributes if c not in df.columns]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f5cd7b-882c-40db-b12d-87bc810e6e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = os.path.join(BASE_DIR, 'data', 'runoff_prediction_results')\n",
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b0fc7d-115a-4749-bd26-8c1edc973e6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_runoff_from_attributes(df, train_indices, test_indices, group_order, results_folder):\n",
    "        \n",
    "    # set the target column\n",
    "    target_column = f'mean_runoff'\n",
    "    test_attributes = []\n",
    "\n",
    "    # add attribute groups successively\n",
    "    for set_name in group_order:\n",
    "        attribute_set = attribute_set_dict[set_name]\n",
    "        print(f' Processing {set_name} attribute set')\n",
    "        test_attributes += attribute_set\n",
    "        input_data = df[test_attributes + [target_column]].copy()\n",
    "\n",
    "        # run the XGBoost model with cross validation and test on holdout set\n",
    "        trial_df, test_df = dpf.run_xgb_CV_trials(\n",
    "            set_name, test_attributes, target_column, input_data, train_indices, \n",
    "            test_indices, n_optimization_rounds, nfolds, n_boost_rounds, results_folder\n",
    "        )\n",
    "\n",
    "        test_rmse = root_mean_squared_error(test_df['actual'], test_df['predicted'])\n",
    "        test_mae = mean_absolute_error(test_df['actual'], test_df['predicted'])\n",
    "\n",
    "        print(f'  {set_name}')\n",
    "        print(f'   held-out test rmse: {test_rmse:.2f}, mae: {test_mae:.2f}')\n",
    "        print('')\n",
    "        # store the test set predictions and actuals\n",
    "        all_test_results[set_name] = {\n",
    "            'trials': trial_df, 'test_df': test_df,\n",
    "            'test_mae': test_mae, 'test_rmse': test_rmse,\n",
    "        } \n",
    "    return all_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1a16f7-84df-4e42-9acf-b2a990b30812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the amount of data to set aside for final testing\n",
    "holdout_pct = 0.10\n",
    "nfolds = 5\n",
    "n_boost_rounds = 2000\n",
    "n_optimization_rounds = 20\n",
    "\n",
    "all_test_results = {}\n",
    "attribute_set_dict = {\n",
    "    'climate': climate, \n",
    "    '+land_cover': land_cover,\n",
    "    '+terrain': terrain, \n",
    "    '+soil': soil,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec0b64e-34cc-4e51-a349-01caff47d498",
   "metadata": {},
   "source": [
    "## Set Attribute Groupings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9fad8a-2937-463e-aad2-cd2f53259092",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_1 = ['climate', '+terrain', '+land_cover', '+soil']\n",
    "group_2 = group_1[::-1]\n",
    "group_3 = ['+land_cover', '+terrain', '+soil', 'climate']\n",
    "group_4 = ['+soil', 'climate', '+land_cover', '+terrain']\n",
    "attribute_group_orders = [group_1, group_2, group_3, group_4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0cb174-d0ba-4255-9a4a-e5def949dfb9",
   "metadata": {},
   "source": [
    "## Run XGBoost Models\n",
    "\n",
    "Separate the test set at the outset so the attribute group ordering is tested on the same hold-out set but necessarily on unique training optimizations.  This ensures that at least the presence of outliers in the hold-out set should at least be constant across the attribute group reordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ad7999-b675-4657-a9a0-f7239d5427d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the index to ensure the split is done correctly\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "train_indices, test_indices = dpf.train_test_split(df, holdout_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51c3401-0e98-4162-ae4c-b86a7763d30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "group_results = {}\n",
    "for group in attribute_group_orders:\n",
    "    print(f'Processing: {group} ordering.')\n",
    "    n += 1\n",
    "    test_results_fname = f'Mean_runoff_prediction_results_{n}.npy'\n",
    "    test_results_fpath = os.path.join(results_folder, test_results_fname)\n",
    "    if os.path.exists(test_results_fpath):\n",
    "        all_test_results = np.load(test_results_fpath, allow_pickle=True).item()\n",
    "    else:\n",
    "        all_test_results = predict_runoff_from_attributes(df, train_indices, test_indices, group, results_folder)\n",
    "        np.save(test_results_fpath, all_test_results)\n",
    "    \n",
    "    group_results[n] = {'order': group, 'results': all_test_results}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5f4a55-eb98-4006-8bdc-b97f1cfb104b",
   "metadata": {},
   "source": [
    "## View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4557abc-675c-4948-945e-1d593170eace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_results_plots(all_test_results, attribute_sets):\n",
    "    \n",
    "    plots = []\n",
    "\n",
    "    test_rmse, test_mae = [], []\n",
    "\n",
    "    y1 = [all_test_results[e]['test_rmse'] for e in attribute_sets]\n",
    "    y2 = [all_test_results[e]['test_mae'] for e in attribute_sets]\n",
    "\n",
    "    source = ColumnDataSource({'x': attribute_sets, 'y1': y1, 'y2': y2})\n",
    "\n",
    "    title = f'Runoff Predictability'\n",
    "\n",
    "    if len(plots) == 0:\n",
    "        fig = figure(title=title, x_range=attribute_sets)\n",
    "    else:\n",
    "        fig = figure(title=title, x_range=attribute_sets, y_range=plots[0].y_range)\n",
    "    fig.line('x', 'y1', legend_label='rmse', color='green', source=source, line_width=3)\n",
    "    fig.line('x', 'y2', legend_label='mae', color='dodgerblue', source=source, line_width=3)\n",
    "    fig.legend.background_fill_alpha = 0.6\n",
    "    fig.yaxis.axis_label = 'RMSE'\n",
    "\n",
    "    result_df = pd.DataFrame({'set': attribute_sets, 'rmse': y1, 'mae': y2})\n",
    "    best_rmse_idx = result_df['rmse'].idxmin()\n",
    "    best_mae_idx = result_df['mae'].idxmin()\n",
    "    best_rmse_set = result_df.loc[best_rmse_idx, 'set']\n",
    "    best_mae_set = result_df.loc[best_mae_idx, 'set']\n",
    "    best_result = all_test_results[best_rmse_set]['test_df']\n",
    "\n",
    "    xx, yy = best_result['actual'], best_result['predicted']\n",
    "    slope, intercept, r, p, se = linregress(xx, yy)\n",
    "\n",
    "    sfig = figure(title=f'Test: best model {best_rmse_set} (N={len(best_result)})',\n",
    "                 )\n",
    "    sfig.scatter(xx, yy, size=3, alpha=0.8)\n",
    "    x_obs = np.linspace(min(xx), max(xx), 1000)\n",
    "    ybf = [slope * e + intercept for e in x_obs]\n",
    "    sfig.line(x_obs, ybf, color='red', line_width=3, line_dash='dashed', legend_label=f'RÂ²={r**2:.2f}')    \n",
    "    sfig.xaxis.axis_label = r'$$\\text{Observed Mean} \\left[ m^3 / s \\right]$$'\n",
    "    sfig.yaxis.axis_label = r'$$\\text{Predicted Mean} \\left[ m^3 / s \\right]$$'\n",
    "    sfig.legend.location = 'top_left'\n",
    "    plots.append(fig)\n",
    "    plots.append(sfig)\n",
    "    \n",
    "    # plot a 1:1 line\n",
    "    sfig.line([0, max(ybf)], [0, max(ybf)], color='black', line_dash='dotted', \n",
    "              line_width=2, legend_label='1:1')\n",
    "    \n",
    "    return plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eed93bf-4428-46f2-851c-58964ffc75f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "grp_1_plots = create_results_plots(group_results[n]['results'], group_results[n]['order'])\n",
    "layout = gridplot(grp_1_plots, ncols=2, width=350, height=300)\n",
    "show(layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a87ca0-9f51-43b2-9304-f7c4d77dec89",
   "metadata": {},
   "source": [
    "### Test the sensitivity to Order of attribute groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf102058-f2c1-4618-9f63-a1295d2fa071",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "grp_2_plots = create_results_plots(group_results[n]['results'], group_results[n]['order'])\n",
    "layout = gridplot(grp_2_plots, ncols=2, width=350, height=300)\n",
    "show(layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65045b7c-1806-43f4-918a-88dbd12dc62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "grp_3_plots = create_results_plots(group_results[n]['results'], group_results[n]['order'])\n",
    "layout = gridplot(grp_3_plots, ncols=2, width=350, height=300)\n",
    "show(layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8448c7-e027-49b8-bfc6-0c7e5a2c1313",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "grp_4_plots = create_results_plots(group_results[n]['results'], group_results[n]['order'])\n",
    "layout = gridplot(grp_4_plots, ncols=2, width=350, height=300)\n",
    "show(layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1593627-9a0b-492b-b7d9-f38f47373ca0",
   "metadata": {},
   "source": [
    "### Test randomly permuted target values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6205f3-f7c3-4e3a-8567-0d6607995674",
   "metadata": {},
   "source": [
    "As a last iteration, randomize the order of the mean_runoff column to test what the algorithm is learning.\n",
    "\n",
    "The predictive power decreases substantially across all groupings of input attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374287fd-d83d-49d5-8df9-f57ab64e616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_fname = f'Mean_runoff_prediction_results_shuffled_Y.npy'\n",
    "test_results_fpath = os.path.join('data', test_results_fname)\n",
    "if os.path.exists(test_results_fpath):\n",
    "    all_test_results = np.load(test_results_fpath, allow_pickle=True).item()\n",
    "else:\n",
    "    shuffled_df = df.copy()\n",
    "    runoff_values = df['mean_runoff'].values\n",
    "    # randomly shuffle the order of runoff values\n",
    "    np.random.shuffle(runoff_values)\n",
    "    shuffled_df['mean_runoff'] = runoff_values\n",
    "    all_test_results = predict_runoff_from_attributes(shuffled_df, train_indices, test_indices, group, results_folder)\n",
    "    np.save(test_results_fpath, all_test_results)\n",
    "\n",
    "group_results['shuffled'] = {'order': group_1, 'results': all_test_results}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362e6084-b3d6-42dd-ad55-f1a7fe0b1c5e",
   "metadata": {},
   "source": [
    "### View results of shuffled target variable (mean runoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19599ae9-a6bd-4362-883a-d094c833df3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_results = group_results['shuffled']['results']\n",
    "group_order = group_results['shuffled']['order']\n",
    "shuffled_runoff_plots = create_results_plots(shuffled_results, group_order)\n",
    "layout = gridplot(shuffled_runoff_plots, ncols=2, width=350, height=300)\n",
    "show(layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ffc38f-a4fb-4a65-80fc-e8ac81a9548c",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "- Reordering the attribute groupings suggests there are interactions between attributes in model training.  \n",
    "- Across all orderings, the terrain attributes appear to be the best predictors, and surprisingly the climate attributes are not.  \n",
    "- Randomly permuting the order of the target variable, `mean_runoff` erases all predictive power.\n",
    "\n",
    "### Need to test sensitivity to hold-out set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726a1db2-7b71-45e5-859b-fc3cbd7f0a87",
   "metadata": {},
   "source": [
    "## Citations\n",
    "\n",
    "```{bibliography}\n",
    ":filter: docname in docnames\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
