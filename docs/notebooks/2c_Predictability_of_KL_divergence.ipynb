{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0bd3e2d-4130-4fd8-8d0e-aebdadd4d447",
   "metadata": {},
   "source": [
    "# Predictability of Kullback-Leibler (KL) Divergence\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Streamflow prediction in ungauged basins has classically focused on minimizing one or more loss functions, typically square error, NSE, and KGE, between observed (daily streamflow) values and predictions generated by some type of model, whether it be an empirical regionalization, statistical machine learning, or process-based rainfall runoff model.  Regionalization and machine learning models depend upon an existing streamflow monitoring network for PUB, and the performance of these models is linked to the existing network's representativeness of the ungauged space.  This link raises the question how varying the network arrangement affects the performance of PUB models *overall* in terms of an expectation of prediction error, that is prediction error across all ungauged locations, and by extension whether there exist environmental signals orthogonal to streamflow with sufficient information to discriminate between network arrangements to minimize the expectation of prediction error over the ungagued space.  \n",
    "\n",
    "A simple interpretation of the loss functions commonly used in the PUB literature might be \"how close are mean daily streamflow predictions to observed values?\"  A much simpler question to ask of observational data is: \"will a given model outperform random guessing in the long run?\".  This binary question represents a starting point to approach the optimal streamflow monitoring network problem.  The justification for asking such a basic question is that an expectation of the uncertainty reduction over the unmonitored space provided by a given monitoring arrangement supports a discriminant function to compare unique arrangements.  In addition, more complex questions quickly become intractable given that the number of comparisons grows exponentially with the size of the decision space (possible monitoring locations).  A simple, informative problem formulation is then possible to test on real data, in this case an ungauged space of over 1 million ungauged catchments and a set of over 1600 monitored catchments with which to train a model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df599a40-f7df-4c3e-a91e-bd7a959b0a30",
   "metadata": {},
   "source": [
    "## Problem Formulation\n",
    "\n",
    "The question \"is a given model better than random guessing in the long run\" is formulated into a binary classification problem as follows: \n",
    "\n",
    "* The streamflow prediction model assumes that discharge at one location is equal to that a different lcoation on a unit area basis, commonly referred to as an equal unit area runoff (UAR) model.\n",
    "* Given the equal UAR model, an observed (proxy) catchment is a potential model for predicting the distribution of UAR for any unobserved (target) location,\n",
    "* A proxy is \"informative\" to a target if the proxy UAR is closer to the posterior target UAR than the maximum uncertainty (uniform distribution) prior.\n",
    "* A proxy is \"disinformative\" to a target if the maximum uncertainty (uniform distribution) prior is closer to the posterior target UAR than the proxy UAR.\n",
    "* The \"closeness\" of distributions is characterized by three measures from the general class of f-divergences, namely the total variation distance (TVD), the Kullback-Leibler divergence ($D_{KL}$), and the earth mover's distance (EMD), also known as the Wasserstein distance.\n",
    "\n",
    "For the Kullback-Leibler divergence $D_{KL}$:\n",
    "* The (posterior) target UAR distribution is denoted by $P$, and the proxy UAR distribution (model) is denoted by $Q$.\n",
    "* A proxy model is informative for some target location if $D_{KL}(P||\\mathbb{U}) - D_{KL}(P||Q) > 0$\n",
    "   \n",
    "\n",
    "The binary problem formulation is then:\n",
    "* The discriminant function maps the difference in the two divergences to a binary outcome corresponding to the sign of the resulting quantity $Y = +1 \\text{ if } D_{KL}(P||\\mathbb{U}) - D_{KL}(P||Q) > 0 \\text{ or } -1 \\text{ otherwise}$\n",
    "* The goal is to miminize the probability of incorrect predictions, defined by the (Bayes) error $R_{\\textbf{Bayes}}(\\gamma, C) := \\mathbb{P} \\left(Y \\neq \\text{sign}(D_{KL}(\\mathbf{P}||\\mathbb{U}) - D_{KL}(\\mathbf{P}||\\mathbf{Q}) \\right)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621f91ed-81b9-43cc-a84b-419f89e21d68",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The model used to generate streamflow predictions is likewise simple. \n",
    "\n",
    "The equal unit area runoff (EUAR) model assumes that discharge at one location is equal to that at another on a unit area basis.  The EUAR model is widely used since it is a reasonable first approximation where catchments are nested, are in close proximity, or are similar in terms of the processes that govern the rainfall-runoff response.  Indices describing physical characteristics related to runoff process controls have long been used in PUB.  Where past work has focused on predicting streamflow itself (citation), or on predicting hydrological signatures defined as scalar indices that are said to encapsulate processes, we take a different approach to predict aggregate system behaviour.\n",
    "\n",
    "The EAUR model is translated to the binary classification problem by assuming that \n",
    "\n",
    "The question \"will a model be better than random guessing\" is formulated by assuming In order to map the prediction of streamflow to a binary label $\\mathcal{Y}$, .  \n",
    "\n",
    "-The EUAR model is profiled by its expected prediction compared to \"random guessing\".  \n",
    "\n",
    "In the previous section, we mapped streamflow to entropy as a quantity describing the randomness of river systems.  Since the (Shannon) entropy of the distribution does not embody one specific process, it does not fit with conventional classifications of hydrological signatures.  Since it encompasses the entire distribution, the entropy represents some aggregate characteristic that does not attempt to disentangle the highly interrelated confounds of the hydrologic cycle.\n",
    "\n",
    "This is accomplished by comparing unit area runoff (UAR) distributions in terms of \n",
    "\n",
    "Conversely, this model produces predictions that are worse than random guessing, as we will show using a surrogate loss functions  from the information theory literature. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee1a956-74d7-4320-b6ea-1e372b30267a",
   "metadata": {},
   "source": [
    "This binary classification formulation brings the optimal (streamflow) sensor placement question into the domain of signal processing where much work has been done to prove statistical consistency using surrogate loss functions, substitutes for the non-convex 0-1 loss function.  \n",
    "\n",
    "In the first steps, we looked at the predictability of a common hydrological signature and an uncommon information measure, both computed on individual distributions.  If the entropy measure is reasonably predictable from attributes, then the uncertainty of unmonitored locations might be predictable enough for some applications.  \n",
    "\n",
    "Here we make a comparison of runoff between large samples of **location pairs** and ask if: \n",
    "\n",
    "1) it can be predicted whether a monitored catchment is a better model for a target catchment compared to random guessing.\n",
    "2) The **Kullback-Leibler Divergence** (KLD) of the distribution of unit area runoff between two locations can be predicted from the attributes of both catchments (and their differences).\n",
    "\n",
    "\n",
    "We continue to use the gradient boosted decision tree method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bccb102-9f10-4f22-80bd-4c60ab954d61",
   "metadata": {},
   "source": [
    "### Experimental setup\n",
    "\n",
    "The decision of where to place sensors to optimize the monitoring of a random field relies on estimating a function $\\gamma$ that maps a d-dimensional covariate vector $X$ to some label or value $Y$ that must be consistently predictable in order to make decisions.  Estimating the discriminant function $\\gamma$ that predicts $Y$ is one part of the problem.  The other part of the problem is to determine a suitable (convex) loss function such that empirical risk minimization procedures such as support vector machines and gradient boosting can be applied.  {cite}`nguyen2009surrogate` describes the relationship between surrogate loss functions and another class of functions called f-divergences.\n",
    " \n",
    "In the case of the streamflow monitoring network, the goal is to maximize the information that the total monitoring network captures about the total unmonitored space. Stated differently, the aim is to determine the set of streamflow monitoring locations that yields the greatest reduction in uncertainty over the total space.  The total space is defined as any location in a river network that can be monitored, and we represent this space by the set of confluences of a river network over a regional/continental scale.  The baseline for estimating the reduction in uncertainty is, maximum uncertainty, the uniform distribution.  Examples of discriminant-loss function pairs $\\gamma \\rightarrow \\ell$ include:\n",
    "\n",
    "\n",
    "* $\\gamma$ predict streamflow at unmonitored locations using a parameterized rainfall runoff model with:\n",
    "    * $\\ell$: SSE, MAE, MSE, NSE, KGE, etc.\n",
    "* $\\gamma$\n",
    "\n",
    "The discriminant function is the mapping of inputs to scalar valued outputs such that a loss can be computed.  In the optimial sensor network problem, each possible monitoring location is evaluated for its potential to reduce uncertainty at all other unmonitored locations.  A (proxy) location is evaluated for its utility in reducing uncertainty at another (target) location by a model which takes in a d-dimensional covariate vector of catchment attributes $\\mathbb{X}$ describing both the proxy and target locations, and a .\n",
    "\n",
    "## Binary Classification\n",
    "\n",
    "{cite}`nguyen2009surrogate` describes the general binary classification problem as finding a discriminant function to predict $\\mathcal{Y} = \\{ -1, +1 \\}$ from a covariate vector $\\mathcal{X}$ given a sample of observations $\\{(X_1, Y_1), \\dots, (X_n, Y_n)\\}$, $(X, Y) \\in (\\mathcal{X}, \\mathcal{Y})$. The aim of the binary classification problem is to minimize the expectation of the 0-1 loss $\\mathbb{P}(Y \\neq \\text{sign}(\\gamma (X)))$ where the notation $\\text{sign}(\\alpha) = 1 \\text{ if } \\alpha > 0 \\text{ else } -1$ follows {cite}`nguyen2009surrogate`.\n",
    "\n",
    "\n",
    "The goal is to minimize the risk of bad predictions, and the problem is to simultaneously determine both the mapping $\\mathbf{C}$ of continous streamflow $\\mathbf{S}$ to a discrete set of state symbols $\\mathbf{Z}$\n",
    "\n",
    "The goal is to miminize the (Bayes) error $R_{\\textbf{Bayes}}(\\gamma, C) := \\mathbb{P} \\left(Y \\neq \\text{sign}(D_{KL}(\\mathbf{P}||\\mathbb{U}) - D_{KL}(\\mathbf{P}||\\mathbf{Q}) \\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c9864ab-af00-457b-bfe0-2e69ac18b2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"af3469ee-456f-4e1c-a4c0-361c45029e6c\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "'use strict';\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    function drop(id) {\n",
       "      const view = Bokeh.index.get_by_id(id)\n",
       "      if (view != null) {\n",
       "        view.model.document.clear()\n",
       "        Bokeh.index.delete(view)\n",
       "      }\n",
       "    }\n",
       "\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null) {\n",
       "      drop(id)\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim()\n",
       "            drop(id)\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded(error = null) {\n",
       "    const el = document.getElementById(\"af3469ee-456f-4e1c-a4c0-361c45029e6c\");\n",
       "    if (el != null) {\n",
       "      const html = (() => {\n",
       "        if (typeof root.Bokeh === \"undefined\") {\n",
       "          if (error == null) {\n",
       "            return \"BokehJS is loading ...\";\n",
       "          } else {\n",
       "            return \"BokehJS failed to load.\";\n",
       "          }\n",
       "        } else {\n",
       "          const prefix = `BokehJS ${root.Bokeh.version}`;\n",
       "          if (error == null) {\n",
       "            return `${prefix} successfully loaded.`;\n",
       "          } else {\n",
       "            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n",
       "          }\n",
       "        }\n",
       "      })();\n",
       "      el.innerHTML = html;\n",
       "\n",
       "      if (error != null) {\n",
       "        const wrapper = document.createElement(\"div\");\n",
       "        wrapper.style.overflow = \"auto\";\n",
       "        wrapper.style.height = \"5em\";\n",
       "        wrapper.style.resize = \"vertical\";\n",
       "        const content = document.createElement(\"div\");\n",
       "        content.style.fontFamily = \"monospace\";\n",
       "        content.style.whiteSpace = \"pre-wrap\";\n",
       "        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n",
       "        content.textContent = error.stack ?? error.toString();\n",
       "        wrapper.append(content);\n",
       "        el.append(wrapper);\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(() => display_loaded(error), 100);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.4.1.min.js\"];\n",
       "  const css_urls = [];\n",
       "\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      try {\n",
       "            for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "\n",
       "      } catch (error) {display_loaded(error);throw error;\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"af3469ee-456f-4e1c-a4c0-361c45029e6c\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(\"af3469ee-456f-4e1c-a4c0-361c45029e6c\");\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.4.1.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {display_loaded(error);throw error;\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"af3469ee-456f-4e1c-a4c0-361c45029e6c\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.palettes import Sunset10, Vibrant7\n",
    "\n",
    "import xgboost as xgb\n",
    "xgb.config_context(verbosity=2)\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    root_mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    ")\n",
    "\n",
    "import data_processing_functions as dpf\n",
    "\n",
    "from scipy.stats import linregress\n",
    "output_notebook()\n",
    "\n",
    "BASE_DIR = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a42fc6-9ff0-4f8e-b904-d73810419b8a",
   "metadata": {},
   "source": [
    "### Load attribute data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36488ad5-32a9-4d0a-b8ae-64967236e839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1609 monitored basins in the attribute set.\n"
     ]
    }
   ],
   "source": [
    "# load the catchment characteristics\n",
    "fname = 'BCUB_watershed_attributes_updated.csv'\n",
    "attr_df = pd.read_csv(os.path.join('data', fname))\n",
    "attr_df.columns = [c.lower() for c in df.columns]\n",
    "station_ids = attr_df['official_id'].values\n",
    "print(f'There are {len(station_ids)} monitored basins in the attribute set.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cc3d94-dc6d-43e8-a308-fe5e4c6b7c84",
   "metadata": {},
   "source": [
    "### Load pairwise attribute comparisons\n",
    "\n",
    "Load a few rows from one of the pairwise data files.  These contain attributes about divergence measures that are computed on concurrent and non-concurrent time series at two monitored locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dee077b8-18d1-4d0d-979b-c59cb5518c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open an example pairwise results file\n",
    "input_folder = os.path.join(\n",
    "    BASE_DIR, \"data\", \"processed_divergence_inputs\",\n",
    ")\n",
    "pairs_files = os.listdir(input_folder)\n",
    "test_df = pd.read_csv(os.path.join(input_folder, pairs_files[0]), nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89f6295a-9d60-4667-bb7a-9ac6a41d0522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dkl_concurrent_uniform',\n",
       " 'dkl_concurrent_post_-5R',\n",
       " 'dkl_concurrent_post_-4R',\n",
       " 'dkl_concurrent_post_-3R',\n",
       " 'dkl_concurrent_post_-2R',\n",
       " 'dkl_concurrent_post_-1R',\n",
       " 'dkl_concurrent_post_0R',\n",
       " 'dkl_concurrent_post_1R',\n",
       " 'dkl_concurrent_post_2R',\n",
       " 'dkl_concurrent_post_3R',\n",
       " 'dkl_concurrent_post_4R',\n",
       " 'dkl_concurrent_post_5R',\n",
       " 'dkl_concurrent_post_6R',\n",
       " 'dkl_concurrent_post_7R',\n",
       " 'dkl_concurrent_post_8R',\n",
       " 'dkl_concurrent_post_9R',\n",
       " 'dkl_concurrent_post_10R',\n",
       " 'dkl_nonconcurrent_uniform',\n",
       " 'dkl_nonconcurrent_post_-5R',\n",
       " 'dkl_nonconcurrent_post_-4R',\n",
       " 'dkl_nonconcurrent_post_-3R',\n",
       " 'dkl_nonconcurrent_post_-2R',\n",
       " 'dkl_nonconcurrent_post_-1R',\n",
       " 'dkl_nonconcurrent_post_0R',\n",
       " 'dkl_nonconcurrent_post_1R',\n",
       " 'dkl_nonconcurrent_post_2R',\n",
       " 'dkl_nonconcurrent_post_3R',\n",
       " 'dkl_nonconcurrent_post_4R',\n",
       " 'dkl_nonconcurrent_post_5R',\n",
       " 'dkl_nonconcurrent_post_6R',\n",
       " 'dkl_nonconcurrent_post_7R',\n",
       " 'dkl_nonconcurrent_post_8R',\n",
       " 'dkl_nonconcurrent_post_9R',\n",
       " 'dkl_nonconcurrent_post_10R']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kld_columns = [c for c in test_df.columns if 'dkl' in c]\n",
    "kld_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1dfec8-2810-4d35-b33e-00c58c3eb869",
   "metadata": {},
   "source": [
    "### Define attribute groupings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5dc872c-e2cb-475b-9366-f57b1e1409d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terrain = ['drainage_area_km2', 'elevation_m', 'slope_deg', 'aspect_deg'] #'gravelius', 'perimeter',\n",
    "land_cover = [\n",
    "    'land_use_forest_frac_2010', 'land_use_grass_frac_2010', 'land_use_wetland_frac_2010', 'land_use_water_frac_2010', \n",
    "    'land_use_urban_frac_2010', 'land_use_shrubs_frac_2010', 'land_use_crops_frac_2010', 'land_use_snow_ice_frac_2010']\n",
    "soil = ['logk_ice_x100', 'porosity_x100']\n",
    "climate = ['prcp', 'srad', 'swe', 'tmax', 'tmin', 'vp', 'high_prcp_freq', 'high_prcp_duration', 'low_prcp_freq', 'low_prcp_duration']\n",
    "all_attributes = terrain + land_cover + soil + climate\n",
    "len(all_attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bb16a8-bd98-4c6f-b786-b8d0e8bd36a7",
   "metadata": {},
   "source": [
    "### Set trial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a10314ed-631c-43cf-9f7a-4ea9ea6de8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the amount of data to set aside for final testing\n",
    "holdout_pct = 0.10\n",
    "nfolds = 5\n",
    "n_boost_rounds = 2500\n",
    "n_optimization_rounds = 20\n",
    "\n",
    "#define if testing concurrent or nonconcurrent data\n",
    "concurrent = 'concurrent'\n",
    "\n",
    "# the input data file has an associated revision date\n",
    "revision_date = '20240812'\n",
    "\n",
    "all_test_results = {}\n",
    "attribute_set_names = ['climate', '+land_cover', '+terrain', '+soil']\n",
    "\n",
    "results_folder = os.path.join(BASE_DIR, 'data', 'kld_prediction_results')\n",
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81fe86f8-8454-4e81-85d6-f110346f53e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['region', 'official_id', 'drainage_area_km2', 'centroid_lon_deg_e',\n",
       "       'centroid_lat_deg_n', 'logk_ice_x100', 'porosity_x100',\n",
       "       'land_use_forest_frac_2010', 'land_use_shrubs_frac_2010',\n",
       "       'land_use_grass_frac_2010', 'land_use_wetland_frac_2010',\n",
       "       'land_use_crops_frac_2010', 'land_use_urban_frac_2010',\n",
       "       'land_use_water_frac_2010', 'land_use_snow_ice_frac_2010',\n",
       "       'lulc_check_2010', 'land_use_forest_frac_2015',\n",
       "       'land_use_shrubs_frac_2015', 'land_use_grass_frac_2015',\n",
       "       'land_use_wetland_frac_2015', 'land_use_crops_frac_2015',\n",
       "       'land_use_urban_frac_2015', 'land_use_water_frac_2015',\n",
       "       'land_use_snow_ice_frac_2015', 'lulc_check_2015',\n",
       "       'land_use_forest_frac_2020', 'land_use_shrubs_frac_2020',\n",
       "       'land_use_grass_frac_2020', 'land_use_wetland_frac_2020',\n",
       "       'land_use_crops_frac_2020', 'land_use_urban_frac_2020',\n",
       "       'land_use_water_frac_2020', 'land_use_snow_ice_frac_2020',\n",
       "       'lulc_check_2020', 'slope_deg', 'aspect_deg', 'median_el', 'mean_el',\n",
       "       'max_el', 'min_el', 'elevation_m', 'prcp', 'tmin', 'tmax', 'vp', 'swe',\n",
       "       'srad', 'low_prcp_duration', 'low_prcp_freq', 'high_prcp_duration',\n",
       "       'high_prcp_freq', 'mean_runoff'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ad14d45-f773-431f-9f67-82bd77456963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_attributes(attr_df, df_relations, attribute_cols):\n",
    "    \"\"\"\n",
    "    Adds attributes from the df_attributes to the df_relations based on the 'proxy' and 'target' columns\n",
    "    using map for efficient lookups.\n",
    "\n",
    "    Parameters:\n",
    "    df_attributes (pd.DataFrame): DataFrame with 'id' and attribute columns.\n",
    "    df_relations (pd.DataFrame): DataFrame with 'proxy' and 'target' columns.\n",
    "    attribute_cols (list of str): List of attribute columns to add to df_relations.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Updated df_relations with added attribute columns.\n",
    "    \"\"\"\n",
    "    # Create dictionaries for each attribute for quick lookup\n",
    "    attr_dicts = {col: attr_df.set_index('official_id')[col].to_dict() for col in attribute_cols}\n",
    "\n",
    "    # Add target attributes\n",
    "    for col in attribute_cols:\n",
    "        df_relations[f'target_{col}'] = df_relations['target'].map(attr_dicts[col])\n",
    "\n",
    "    # Add proxy attributes\n",
    "    for col in attribute_cols:\n",
    "        df_relations[f'proxy_{col}'] = df_relations['proxy'].map(attr_dicts[col])\n",
    "\n",
    "    return df_relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "667b4c45-cb1d-445c-95e2-65dd657e9fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_KLD_from_attributes(attr_df, target_col, holdout_pct, stations, nfolds, results_folder, partial_counts=False):\n",
    "\n",
    "    training_stn_cv_sets, test_stn_sets = dpf.train_test_split_by_official_id(holdout_pct, stations, nfolds)\n",
    "    all_test_results = {}\n",
    "    for bitrate in [4, 6, 8, 9, 10, 11, 12]:\n",
    "        t0 = time()\n",
    "        print(f'bitrate = {bitrate}')\n",
    "        fname = f\"KL_results_{bitrate}bits_{revision_date}.csv\"\n",
    "        if partial_counts:\n",
    "            fname = f\"KL_results_{bitrate}bits_{revision_date}_partial_counts.csv\"\n",
    "\n",
    "        input_data_fpath = os.path.join(input_folder, fname)\n",
    "        nrows = None\n",
    "        df = pd.read_csv(input_data_fpath, nrows=nrows, low_memory=False)\n",
    "        df.dropna(subset=[target_col], inplace=True)\n",
    "        t1 = time()\n",
    "        print(f'    {t1-t0:.2f}s to load input data')\n",
    "\n",
    "        # add the attributes into the input dataset\n",
    "        df = add_attributes(attr_df, df, all_attributes)\n",
    "        \n",
    "        all_test_results[bitrate] = {}\n",
    "        input_attributes = []\n",
    "\n",
    "        # add attribute groups successively\n",
    "        for attribute_set, set_name in zip([land_cover, terrain, soil, climate], attribute_set_names):\n",
    "            print(f'  Processing {set_name} attribute set: {target_col}')\n",
    "            input_attributes += attribute_set \n",
    "                        \n",
    "            features = dpf.format_features(input_attributes)\n",
    "            \n",
    "            trial_df, test_df = dpf.run_xgb_trials_custom_CV(\n",
    "                bitrate, set_name, features, target_col, df, \n",
    "                training_stn_cv_sets, test_stn_sets, n_optimization_rounds, \n",
    "                nfolds, n_boost_rounds, results_folder\n",
    "            )\n",
    "            \n",
    "            test_rmse = root_mean_squared_error(test_df['actual'], test_df['predicted'])\n",
    "            test_mae = mean_absolute_error(test_df['actual'], test_df['predicted'])\n",
    "\n",
    "            print(f'   held-out test rmse: {test_rmse:.2f}, mae: {test_mae:.2f}')\n",
    "            print('')\n",
    "            # store the test set predictions and actuals\n",
    "            all_test_results[bitrate][set_name] = {\n",
    "                'trials': trial_df, 'test_df': test_df,\n",
    "                'test_mae': test_mae, 'test_rmse': test_rmse} \n",
    "    return all_test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90f43e5-3c86-44d1-8c7b-34349ae460ce",
   "metadata": {},
   "source": [
    "## Run Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4116fb09-2489-4dcf-a6ca-8e00f73b70d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitrate = 4\n",
      "    12.02s to load input data\n",
      "  Processing climate attribute set.\n",
      "    3.08 ± 0.029 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 2.89, mae: 2.00\n",
      "\n",
      "  Processing +land_cover attribute set.\n",
      "    2.34 ± 0.101 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 2.16, mae: 1.44\n",
      "\n",
      "  Processing +terrain attribute set.\n",
      "    2.33 ± 0.107 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 2.12, mae: 1.40\n",
      "\n",
      "  Processing +soil attribute set.\n",
      "    2.11 ± 0.082 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.86, mae: 1.21\n",
      "\n",
      "bitrate = 6\n",
      "    12.24s to load input data\n",
      "  Processing climate attribute set.\n",
      "    3.09 ± 0.034 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 2.86, mae: 2.03\n",
      "\n",
      "  Processing +land_cover attribute set.\n",
      "    2.30 ± 0.081 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 2.09, mae: 1.40\n",
      "\n",
      "  Processing +terrain attribute set.\n",
      "    2.25 ± 0.092 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 2.03, mae: 1.35\n",
      "\n",
      "  Processing +soil attribute set.\n",
      "    2.05 ± 0.065 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.84, mae: 1.23\n",
      "\n",
      "bitrate = 8\n",
      "    12.19s to load input data\n",
      "  Processing climate attribute set.\n",
      "    3.21 ± 0.060 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 2.95, mae: 2.21\n",
      "\n",
      "  Processing +land_cover attribute set.\n",
      "    2.24 ± 0.065 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.99, mae: 1.34\n",
      "\n",
      "  Processing +terrain attribute set.\n",
      "    2.23 ± 0.067 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.92, mae: 1.30\n",
      "\n",
      "  Processing +soil attribute set.\n",
      "    2.02 ± 0.048 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.76, mae: 1.19\n",
      "\n",
      "bitrate = 9\n",
      "    12.29s to load input data\n",
      "  Processing climate attribute set.\n",
      "    3.32 ± 0.076 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 3.09, mae: 2.40\n",
      "\n",
      "  Processing +land_cover attribute set.\n",
      "    2.24 ± 0.054 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 2.02, mae: 1.40\n",
      "\n",
      "  Processing +terrain attribute set.\n",
      "    2.23 ± 0.057 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.95, mae: 1.35\n",
      "\n",
      "  Processing +soil attribute set.\n",
      "    2.04 ± 0.043 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.77, mae: 1.23\n",
      "\n",
      "bitrate = 10\n",
      "    12.09s to load input data\n",
      "  Processing climate attribute set.\n",
      "    3.46 ± 0.086 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 3.22, mae: 2.56\n",
      "\n",
      "  Processing +land_cover attribute set.\n",
      "    2.26 ± 0.050 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.96, mae: 1.40\n",
      "\n",
      "  Processing +terrain attribute set.\n",
      "    2.24 ± 0.057 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.93, mae: 1.38\n",
      "\n",
      "  Processing +soil attribute set.\n",
      "    2.06 ± 0.045 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.77, mae: 1.25\n",
      "\n",
      "bitrate = 11\n",
      "    12.36s to load input data\n",
      "  Processing climate attribute set.\n",
      "    3.60 ± 0.082 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 3.38, mae: 2.74\n",
      "\n",
      "  Processing +land_cover attribute set.\n",
      "    2.26 ± 0.055 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 2.05, mae: 1.49\n",
      "\n",
      "  Processing +terrain attribute set.\n",
      "    2.25 ± 0.058 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.96, mae: 1.43\n",
      "\n",
      "  Processing +soil attribute set.\n",
      "    2.10 ± 0.045 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.86, mae: 1.35\n",
      "\n",
      "bitrate = 12\n",
      "    12.49s to load input data\n",
      "  Processing climate attribute set.\n",
      "    3.76 ± 0.074 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 3.57, mae: 2.96\n",
      "\n",
      "  Processing +land_cover attribute set.\n",
      "    2.31 ± 0.055 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 2.01, mae: 1.47\n",
      "\n",
      "  Processing +terrain attribute set.\n",
      "    2.29 ± 0.051 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 2.02, mae: 1.48\n",
      "\n",
      "  Processing +soil attribute set.\n",
      "    2.14 ± 0.042 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.86, mae: 1.35\n",
      "\n",
      "bitrate = 4\n",
      "    12.49s to load input data\n",
      "  Processing climate attribute set.\n",
      "    2.48 ± 0.153 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 2.49, mae: 1.73\n",
      "\n",
      "  Processing +land_cover attribute set.\n",
      "    1.91 ± 0.165 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.86, mae: 1.26\n",
      "\n",
      "  Processing +terrain attribute set.\n",
      "    1.89 ± 0.160 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.85, mae: 1.24\n",
      "\n",
      "  Processing +soil attribute set.\n",
      "    1.73 ± 0.148 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.68, mae: 1.09\n",
      "\n",
      "bitrate = 6\n",
      "    12.28s to load input data\n",
      "  Processing climate attribute set.\n",
      "    2.43 ± 0.130 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 2.46, mae: 1.74\n",
      "\n",
      "  Processing +land_cover attribute set.\n",
      "    1.81 ± 0.147 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.77, mae: 1.22\n",
      "\n",
      "  Processing +terrain attribute set.\n",
      "    1.82 ± 0.148 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.79, mae: 1.23\n",
      "\n",
      "  Processing +soil attribute set.\n",
      "    1.64 ± 0.139 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.72, mae: 1.14\n",
      "\n",
      "bitrate = 8\n",
      "    12.33s to load input data\n",
      "  Processing climate attribute set.\n",
      "    2.46 ± 0.119 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 2.46, mae: 1.81\n",
      "\n",
      "  Processing +land_cover attribute set.\n",
      "    1.75 ± 0.130 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.76, mae: 1.22\n",
      "\n",
      "  Processing +terrain attribute set.\n",
      "    1.74 ± 0.137 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.69, mae: 1.17\n",
      "\n",
      "  Processing +soil attribute set.\n",
      "    1.59 ± 0.124 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.61, mae: 1.08\n",
      "\n",
      "bitrate = 9\n",
      "    12.13s to load input data\n",
      "  Processing climate attribute set.\n",
      "    2.51 ± 0.116 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 2.51, mae: 1.89\n",
      "\n",
      "  Processing +land_cover attribute set.\n",
      "    1.73 ± 0.122 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.72, mae: 1.21\n",
      "\n",
      "  Processing +terrain attribute set.\n",
      "    1.73 ± 0.127 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.69, mae: 1.17\n",
      "\n",
      "  Processing +soil attribute set.\n",
      "    1.58 ± 0.119 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.57, mae: 1.08\n",
      "\n",
      "bitrate = 10\n",
      "    12.30s to load input data\n",
      "  Processing climate attribute set.\n",
      "    2.57 ± 0.112 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 2.60, mae: 2.00\n",
      "\n",
      "  Processing +land_cover attribute set.\n",
      "    1.72 ± 0.120 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.72, mae: 1.22\n",
      "\n",
      "  Processing +terrain attribute set.\n",
      "    1.72 ± 0.123 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.69, mae: 1.19\n",
      "\n",
      "  Processing +soil attribute set.\n",
      "    1.58 ± 0.119 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.59, mae: 1.10\n",
      "\n",
      "bitrate = 11\n",
      "    12.43s to load input data\n",
      "  Processing climate attribute set.\n",
      "    2.64 ± 0.107 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 2.68, mae: 2.10\n",
      "\n",
      "  Processing +land_cover attribute set.\n",
      "    1.71 ± 0.114 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.71, mae: 1.21\n",
      "\n",
      "  Processing +terrain attribute set.\n",
      "    1.71 ± 0.129 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.70, mae: 1.19\n",
      "\n",
      "  Processing +soil attribute set.\n",
      "    1.59 ± 0.109 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.62, mae: 1.13\n",
      "\n",
      "bitrate = 12\n",
      "    12.34s to load input data\n",
      "  Processing climate attribute set.\n",
      "    2.73 ± 0.103 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 2.76, mae: 2.20\n",
      "\n",
      "  Processing +land_cover attribute set.\n",
      "    1.71 ± 0.118 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.77, mae: 1.26\n",
      "\n",
      "  Processing +terrain attribute set.\n",
      "    1.73 ± 0.118 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.70, mae: 1.19\n",
      "\n",
      "  Processing +soil attribute set.\n",
      "    1.61 ± 0.107 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.59, mae: 1.11\n",
      "\n",
      "bitrate = 4\n",
      "    12.96s to load input data\n",
      "  Processing climate attribute set.\n",
      "    1.89 ± 0.078 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.97, mae: 1.44\n",
      "\n",
      "  Processing +land_cover attribute set.\n",
      "    1.41 ± 0.102 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.32, mae: 0.93\n",
      "\n",
      "  Processing +terrain attribute set.\n",
      "    1.41 ± 0.101 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.35, mae: 0.94\n",
      "\n",
      "  Processing +soil attribute set.\n",
      "    1.26 ± 0.083 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.19, mae: 0.82\n",
      "\n",
      "bitrate = 6\n",
      "    12.83s to load input data\n",
      "  Processing climate attribute set.\n",
      "    1.81 ± 0.062 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.88, mae: 1.38\n",
      "\n",
      "  Processing +land_cover attribute set.\n",
      "    1.32 ± 0.088 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.25, mae: 0.88\n",
      "\n",
      "  Processing +terrain attribute set.\n",
      "    1.32 ± 0.085 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.27, mae: 0.88\n",
      "\n",
      "  Processing +soil attribute set.\n",
      "    1.19 ± 0.071 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.09, mae: 0.75\n",
      "\n",
      "bitrate = 8\n",
      "    12.75s to load input data\n",
      "  Processing climate attribute set.\n",
      "    1.77 ± 0.044 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.82, mae: 1.34\n",
      "\n",
      "  Processing +land_cover attribute set.\n",
      "    1.27 ± 0.069 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.17, mae: 0.81\n",
      "\n",
      "  Processing +terrain attribute set.\n",
      "    1.26 ± 0.063 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.19, mae: 0.83\n",
      "\n",
      "  Processing +soil attribute set.\n",
      "    1.16 ± 0.053 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.06, mae: 0.73\n",
      "\n",
      "bitrate = 9\n",
      "    12.48s to load input data\n",
      "  Processing climate attribute set.\n",
      "    1.78 ± 0.041 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.83, mae: 1.34\n",
      "\n",
      "  Processing +land_cover attribute set.\n",
      "    1.28 ± 0.064 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.17, mae: 0.82\n",
      "\n",
      "  Processing +terrain attribute set.\n",
      "    1.25 ± 0.059 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.17, mae: 0.81\n",
      "\n",
      "  Processing +soil attribute set.\n",
      "    1.15 ± 0.051 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.03, mae: 0.73\n",
      "\n",
      "bitrate = 10\n",
      "    12.52s to load input data\n",
      "  Processing climate attribute set.\n",
      "    1.81 ± 0.040 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.85, mae: 1.36\n",
      "\n",
      "  Processing +land_cover attribute set.\n",
      "    1.27 ± 0.067 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.18, mae: 0.85\n",
      "\n",
      "  Processing +terrain attribute set.\n",
      "    1.26 ± 0.063 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.21, mae: 0.86\n",
      "\n",
      "  Processing +soil attribute set.\n",
      "    1.17 ± 0.043 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.08, mae: 0.77\n",
      "\n",
      "bitrate = 11\n",
      "    12.50s to load input data\n",
      "  Processing climate attribute set.\n",
      "    1.86 ± 0.039 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.90, mae: 1.42\n",
      "\n",
      "  Processing +land_cover attribute set.\n",
      "    1.31 ± 0.060 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.20, mae: 0.89\n",
      "\n",
      "  Processing +terrain attribute set.\n",
      "    1.29 ± 0.062 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.22, mae: 0.90\n",
      "\n",
      "  Processing +soil attribute set.\n",
      "    1.21 ± 0.040 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.11, mae: 0.82\n",
      "\n",
      "bitrate = 12\n",
      "    12.40s to load input data\n",
      "  Processing climate attribute set.\n",
      "    1.91 ± 0.042 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.95, mae: 1.46\n",
      "\n",
      "  Processing +land_cover attribute set.\n",
      "    1.35 ± 0.053 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.31, mae: 0.98\n",
      "\n",
      "  Processing +terrain attribute set.\n",
      "    1.34 ± 0.054 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.26, mae: 0.94\n",
      "\n",
      "  Processing +soil attribute set.\n",
      "    1.27 ± 0.042 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.15, mae: 0.87\n",
      "\n",
      "bitrate = 4\n",
      "    12.18s to load input data\n",
      "  Processing climate attribute set.\n",
      "    1.37 ± 0.059 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.26, mae: 0.93\n",
      "\n",
      "  Processing +land_cover attribute set.\n",
      "    1.03 ± 0.046 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 0.93, mae: 0.67\n",
      "\n",
      "  Processing +terrain attribute set.\n",
      "    1.03 ± 0.045 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 0.93, mae: 0.66\n",
      "\n",
      "  Processing +soil attribute set.\n",
      "    0.94 ± 0.044 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 0.82, mae: 0.58\n",
      "\n",
      "bitrate = 6\n",
      "    12.20s to load input data\n",
      "  Processing climate attribute set.\n",
      "    1.28 ± 0.038 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.19, mae: 0.85\n",
      "\n",
      "  Processing +land_cover attribute set.\n",
      "    0.99 ± 0.036 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 0.90, mae: 0.65\n",
      "\n",
      "  Processing +terrain attribute set.\n",
      "    0.98 ± 0.034 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 0.93, mae: 0.67\n",
      "\n",
      "  Processing +soil attribute set.\n",
      "    0.90 ± 0.034 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 0.81, mae: 0.59\n",
      "\n",
      "bitrate = 8\n",
      "    12.17s to load input data\n",
      "  Processing climate attribute set.\n",
      "    1.36 ± 0.036 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.27, mae: 0.93\n",
      "\n",
      "  Processing +land_cover attribute set.\n",
      "    1.10 ± 0.036 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.02, mae: 0.76\n",
      "\n",
      "  Processing +terrain attribute set.\n",
      "    1.10 ± 0.031 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.02, mae: 0.77\n",
      "\n",
      "  Processing +soil attribute set.\n",
      "    1.01 ± 0.035 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 0.91, mae: 0.70\n",
      "\n",
      "bitrate = 9\n",
      "    12.15s to load input data\n",
      "  Processing climate attribute set.\n",
      "    1.48 ± 0.038 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.39, mae: 1.04\n",
      "\n",
      "  Processing +land_cover attribute set.\n",
      "    1.22 ± 0.040 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.12, mae: 0.86\n",
      "\n",
      "  Processing +terrain attribute set.\n",
      "    1.22 ± 0.036 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.12, mae: 0.86\n",
      "\n",
      "  Processing +soil attribute set.\n",
      "    1.14 ± 0.038 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.03, mae: 0.81\n",
      "\n",
      "bitrate = 10\n",
      "    11.97s to load input data\n",
      "  Processing climate attribute set.\n",
      "    1.62 ± 0.039 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.52, mae: 1.18\n",
      "\n",
      "  Processing +land_cover attribute set.\n",
      "    1.36 ± 0.042 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.24, mae: 0.96\n",
      "\n",
      "  Processing +terrain attribute set.\n",
      "    1.35 ± 0.041 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.25, mae: 0.98\n",
      "\n",
      "  Processing +soil attribute set.\n",
      "    1.26 ± 0.038 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.14, mae: 0.90\n",
      "\n",
      "bitrate = 11\n",
      "    12.41s to load input data\n",
      "  Processing climate attribute set.\n",
      "    1.72 ± 0.042 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.63, mae: 1.27\n",
      "\n",
      "  Processing +land_cover attribute set.\n",
      "    1.45 ± 0.046 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.33, mae: 1.04\n",
      "\n",
      "  Processing +terrain attribute set.\n",
      "    1.45 ± 0.045 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.35, mae: 1.06\n",
      "\n",
      "  Processing +soil attribute set.\n",
      "    1.36 ± 0.040 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.23, mae: 0.98\n",
      "\n",
      "bitrate = 12\n",
      "    12.40s to load input data\n",
      "  Processing climate attribute set.\n",
      "    1.79 ± 0.044 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.69, mae: 1.33\n",
      "\n",
      "  Processing +land_cover attribute set.\n",
      "    1.51 ± 0.048 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.38, mae: 1.09\n",
      "\n",
      "  Processing +terrain attribute set.\n",
      "    1.51 ± 0.049 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.39, mae: 1.09\n",
      "\n",
      "  Processing +soil attribute set.\n",
      "    1.43 ± 0.044 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.29, mae: 1.02\n",
      "\n",
      "bitrate = 4\n",
      "    12.59s to load input data\n",
      "  Processing climate attribute set.\n",
      "    0.93 ± 0.041 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 0.81, mae: 0.64\n",
      "\n",
      "  Processing +land_cover attribute set.\n",
      "    0.78 ± 0.028 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 0.71, mae: 0.55\n",
      "\n",
      "  Processing +terrain attribute set.\n",
      "    0.77 ± 0.030 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 0.70, mae: 0.55\n",
      "\n",
      "  Processing +soil attribute set.\n",
      "    0.71 ± 0.025 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 0.67, mae: 0.52\n",
      "\n",
      "bitrate = 6\n",
      "    12.18s to load input data\n",
      "  Processing climate attribute set.\n",
      "    1.17 ± 0.033 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.10, mae: 0.90\n",
      "\n",
      "  Processing +land_cover attribute set.\n",
      "    1.03 ± 0.012 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.01, mae: 0.80\n",
      "\n",
      "  Processing +terrain attribute set.\n",
      "    1.02 ± 0.015 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.01, mae: 0.79\n",
      "\n",
      "  Processing +soil attribute set.\n",
      "    0.96 ± 0.025 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 0.96, mae: 0.74\n",
      "\n",
      "bitrate = 8\n",
      "    12.23s to load input data\n",
      "  Processing climate attribute set.\n",
      "    1.63 ± 0.034 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.60, mae: 1.35\n",
      "\n",
      "  Processing +land_cover attribute set.\n",
      "    1.36 ± 0.017 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.40, mae: 1.13\n",
      "\n",
      "  Processing +terrain attribute set.\n",
      "    1.35 ± 0.019 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.38, mae: 1.10\n",
      "\n",
      "  Processing +soil attribute set.\n",
      "    1.28 ± 0.021 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.34, mae: 1.07\n",
      "\n",
      "bitrate = 9\n",
      "    12.19s to load input data\n",
      "  Processing climate attribute set.\n",
      "    1.86 ± 0.037 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.85, mae: 1.56\n",
      "\n",
      "  Processing +land_cover attribute set.\n",
      "    1.52 ± 0.019 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.57, mae: 1.27\n",
      "\n",
      "  Processing +terrain attribute set.\n",
      "    1.50 ± 0.018 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.55, mae: 1.25\n",
      "\n",
      "  Processing +soil attribute set.\n",
      "    1.42 ± 0.020 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.49, mae: 1.19\n",
      "\n",
      "bitrate = 10\n",
      "    12.08s to load input data\n",
      "  Processing climate attribute set.\n",
      "    2.05 ± 0.039 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 2.05, mae: 1.73\n",
      "\n",
      "  Processing +land_cover attribute set.\n",
      "    1.65 ± 0.017 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.72, mae: 1.40\n",
      "\n",
      "  Processing +terrain attribute set.\n",
      "    1.63 ± 0.016 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.69, mae: 1.36\n",
      "\n",
      "  Processing +soil attribute set.\n",
      "    1.54 ± 0.017 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.64, mae: 1.31\n",
      "\n",
      "bitrate = 11\n",
      "    12.48s to load input data\n",
      "  Processing climate attribute set.\n",
      "    2.17 ± 0.040 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 2.17, mae: 1.83\n",
      "\n",
      "  Processing +land_cover attribute set.\n",
      "    1.74 ± 0.016 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.83, mae: 1.49\n",
      "\n",
      "  Processing +terrain attribute set.\n",
      "    1.72 ± 0.015 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.79, mae: 1.45\n",
      "\n",
      "  Processing +soil attribute set.\n",
      "    1.63 ± 0.015 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.72, mae: 1.38\n",
      "\n",
      "bitrate = 12\n",
      "    12.40s to load input data\n",
      "  Processing climate attribute set.\n",
      "    2.23 ± 0.040 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 2.24, mae: 1.88\n",
      "\n",
      "  Processing +land_cover attribute set.\n",
      "    1.79 ± 0.021 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.86, mae: 1.50\n",
      "\n",
      "  Processing +terrain attribute set.\n",
      "    1.77 ± 0.015 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.85, mae: 1.49\n",
      "\n",
      "  Processing +soil attribute set.\n",
      "    1.67 ± 0.012 RMSE mean on the test set (N=20)\n",
      "   held-out test rmse: 1.78, mae: 1.42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "priors_to_test = [-2, -1, 0, 1, 2]\n",
    "\n",
    "for prior in priors_to_test:\n",
    "    target_col = f'dkl_{concurrent}_post_{prior}R'\n",
    "    test_results_fname = f'{target_col}_{prior}_prior_results.npy'\n",
    "    test_results_fpath = os.path.join(results_folder, test_results_fname)\n",
    "    if os.path.exists(test_results_fpath):\n",
    "        all_test_results = np.load(test_results_fpath, allow_pickle=True).item()\n",
    "    else:\n",
    "        all_test_results = predict_KLD_from_attributes(attr_df, target_col, holdout_pct, station_ids, nfolds, results_folder)\n",
    "        np.save(test_results_fpath, all_test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d6271a5f-d3a0-4194-97e5-fc0aee52649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_result_by_prior(prior):\n",
    "    fname = f'dkl_{concurrent}_post_{prior}R_{prior}_prior_results.npy'\n",
    "    fpath = os.path.join(results_folder, fname)\n",
    "    return np.load(fpath, allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5e405798-b88a-4b3a-87d0-957eb9532ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_dict = {}\n",
    "for prior in priors_to_test:\n",
    "    plots = []\n",
    "    result = load_result_by_prior(prior)\n",
    "    for b, set_dict in result.items():\n",
    "        test_rmse, test_mae = [], []\n",
    "        attribute_sets = list(set_dict.keys())\n",
    "    \n",
    "        y1 = [set_dict[e]['test_rmse'] for e in attribute_sets]\n",
    "        y2 = [set_dict[e]['test_mae'] for e in attribute_sets]\n",
    "        \n",
    "        source = ColumnDataSource({'x': attribute_sets, 'y1': y1, 'y2': y2})\n",
    "        \n",
    "        title = f'{b} bits (Q(θ|D)∼Dirichlet(α10^{prior}_K))'\n",
    "        if len(plots) == 0:\n",
    "            fig = figure(title=title, x_range=attribute_sets)\n",
    "        else:\n",
    "            fig = figure(title=title, x_range=attribute_sets, y_range=plots[0].y_range)\n",
    "        fig.line('x', 'y1', legend_label='rmse', color='green', source=source, line_width=3)\n",
    "        fig.line('x', 'y2', legend_label='mae', color='dodgerblue', source=source, line_width=3)\n",
    "        fig.legend.background_fill_alpha = 0.6\n",
    "        fig.yaxis.axis_label = 'RMSE'\n",
    "        fig.xaxis.axis_label = 'Attribute Group (additive)'\n",
    "        \n",
    "        result_df = pd.DataFrame({'set': attribute_sets, 'rmse': y1, 'mae': y2})\n",
    "        best_rmse_idx = result_df['rmse'].idxmin()\n",
    "        best_mae_idx = result_df['mae'].idxmin()\n",
    "        best_rmse_set = result_df.loc[best_rmse_idx, 'set']\n",
    "        best_mae_set = result_df.loc[best_mae_idx, 'set']\n",
    "        best_result = set_dict[best_rmse_set]['test_df']\n",
    "        \n",
    "        xx, yy = best_result['actual'], best_result['predicted']\n",
    "        slope, intercept, r, p, se = linregress(xx, yy)\n",
    "        \n",
    "        sfig = figure(title=f'Test: {b} bits best model {best_rmse_set} (N={len(best_result)})')\n",
    "        sfig.scatter(xx, yy, size=1, alpha=0.6)\n",
    "        xpred = np.linspace(min(xx), max(xx), 100)\n",
    "        ybf = [slope * e + intercept for e in xpred]\n",
    "        sfig.line(xpred, ybf, color='red', line_width=3, line_dash='dashed', legend_label=f'R²={r**2:.2f}')   \n",
    "        # plot a 1:1 line\n",
    "        sfig.line([min(yy), max(yy)], [min(yy), max(yy)], color='black', line_dash='dotted', \n",
    "                  line_width=2, legend_label='1:1')\n",
    "        sfig.xaxis.axis_label = r'Actual $$D_{KL}$$ [bits/sample]'\n",
    "        sfig.yaxis.axis_label = r'Predicted $$D_{KL}$$ [bits/sample]'\n",
    "        sfig.legend.location = 'top_left'\n",
    "        plots.append(fig)\n",
    "        plots.append(sfig)\n",
    "    layout_dict[prior] = gridplot(plots, ncols=2, width=350, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f81056b-c05a-4e60-a53b-e50cc6c8a920",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(layout_dict[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5502684-7eca-4565-bb7f-6a966909ad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(layout_dict[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9fe488-146d-4007-a40b-6ffed4ea7819",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(layout_dict[-0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7082d28-2f23-4947-971a-a3342830d401",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(layout_dict[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9099e77-470b-4283-97b9-b3e071b0ab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(layout_dict[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f46d97-0f45-4184-9347-3563c410ddf5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fdc7bcd-88cd-45b1-8c47-3a3b0a204046",
   "metadata": {},
   "source": [
    "## Citations\n",
    "\n",
    "```{bibliography}\n",
    ":filter: docname in docnames\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
