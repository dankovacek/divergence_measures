{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5102c59-e6d1-40c9-8fba-3503a7b34cfa",
   "metadata": {},
   "source": [
    "# Predictability of (Shannon) Entropy\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In the previous section, we showed that mean annual discharge could be predicted well from catchment attributes.  In this step we aim to predict a measure of the randomness of river systems from catchment attributes, also known as entropy (H).  Since the (Shannon) entropy of the distribution does not embody one specific process, it does not fit with conventional classifications of hydrological signatures.  Since the entropy measure encompasses the entire distribution, it can be interpreted as an aggregate representation of the complex interactions of the hydrologic cycle.\n",
    "\n",
    "In the data preprocessing, we computed the entropy of the distribution of each individual streamflow time series in bits per sample.  We'll now use an ensemble decision tree method called XGBoost (eXtreme Gradient Boosted decision tree) {cite}`chen2016xgboost` to see if the entropy (or uncertainty) of a distribution can be predicted from catchment attributes.  The dictionary size (number of quantization levels) is varied to test if the additional information in the distribution can be exploited by the model.  The model input features are added in successive model tests to compare the contribution of catchment attribute groups related to climate, terrain, land cover, and soil.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56f760d-4fe7-4a86-bfc4-a9fa56018c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import (\n",
    "    root_mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    ")\n",
    "\n",
    "from scipy.stats import linregress\n",
    "\n",
    "import data_processing_functions as dpf\n",
    "\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.palettes import Sunset10, Vibrant7\n",
    "\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "BASE_DIR = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c7978f-b73a-4abb-8713-158bc2305d7b",
   "metadata": {},
   "source": [
    "## Load Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de943461-f460-47b6-8c5b-16f45e07356f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the catchment characteristics\n",
    "attributes_filename = 'BCUB_watershed_attributes_updated.csv'\n",
    "df = pd.read_csv(os.path.join(BASE_DIR, 'data', 'processed_divergence_inputs', attributes_filename))\n",
    "df.columns = [c.lower() for c in df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3f8dcc-d438-474c-876d-77deb64a2b8f",
   "metadata": {},
   "source": [
    "Subdivide the attributes into related classes: terrain, land cover, soil, climate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86bb960-99c4-48b2-832a-0b3f233d0c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f910853f-477c-42ba-9da6-528bd2ccbc61",
   "metadata": {},
   "source": [
    "## Define Attribute Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407c1113-81ed-4428-a448-8b7f2bd771c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "terrain = ['drainage_area_km2', 'elevation_m', 'slope_deg', 'aspect_deg']\n",
    "land_cover = [\n",
    "    'land_use_forest_frac_2010', 'land_use_grass_frac_2010', 'land_use_wetland_frac_2010', 'land_use_water_frac_2010', \n",
    "    'land_use_urban_frac_2010', 'land_use_shrubs_frac_2010', 'land_use_crops_frac_2010', 'land_use_snow_ice_frac_2010']\n",
    "soil = ['logk_ice_x100', 'porosity_x100']\n",
    "climate = ['prcp', 'srad', 'swe', 'tmax', 'tmin', 'vp', 'high_prcp_freq', 'high_prcp_duration', 'low_prcp_freq', 'low_prcp_duration']\n",
    "all_attributes = terrain + land_cover + soil + climate\n",
    "len(all_attributes)\n",
    "assert len([c for c in all_attributes if c not in df.columns]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6eba15-b8c0-44b4-ab6c-36ab740b750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = os.path.join(BASE_DIR, 'data', 'entropy_prediction_results')\n",
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b0fc7d-115a-4749-bd26-8c1edc973e6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_entropy_from_attributes(df, holdout_pct, results_folder):\n",
    "    df.reset_index(drop=True, inplace=True)    \n",
    "    # randomly select holdout_pct of the stations to leave out for a hold-out test set\n",
    "    # to ensure none of the data are seen in training\n",
    "    train_indices, test_indices = dpf.train_test_split(df, holdout_pct)\n",
    "    all_test_results = {}\n",
    "    for bitrate in [4, 6, 8, 9, 10, 11, 12]:\n",
    "        all_test_results[bitrate] = {}\n",
    "        print(f'bitrate = {bitrate}')\n",
    "        # set the target column\n",
    "        target_column = f'h_{bitrate}_bits'\n",
    "        input_attributes = []\n",
    "\n",
    "        # add attribute groups successively\n",
    "        for attribute_set, set_name in zip([climate, land_cover, terrain, soil], attribute_set_names):\n",
    "            print(f'  Processing {set_name} attribute set.')\n",
    "            input_attributes += attribute_set\n",
    "            input_data = df[input_attributes + [target_column]].copy()\n",
    "\n",
    "            trial_df, test_df = dpf.run_xgb_CV_trials(\n",
    "                set_name, input_attributes, target_column, \n",
    "                input_data, train_indices, test_indices, n_optimization_rounds, \n",
    "                nfolds, n_boost_rounds, results_folder\n",
    "            )\n",
    "            \n",
    "            test_rmse = root_mean_squared_error(test_df['actual'], test_df['predicted'])\n",
    "            test_mae = mean_absolute_error(test_df['actual'], test_df['predicted'])\n",
    "\n",
    "            print(f'    Held-out test rmse: {test_rmse:.2f}, mae: {test_mae:.2f}')\n",
    "            print('')\n",
    "            # store the test set predictions and actuals\n",
    "            all_test_results[bitrate][set_name] = {\n",
    "                'trials': trial_df, 'test_df': test_df,\n",
    "                'test_mae': test_mae, 'test_rmse': test_rmse} \n",
    "    return all_test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04580bbf-8b90-47b4-b29b-210cb7a393f8",
   "metadata": {},
   "source": [
    "## Set Trial Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1a16f7-84df-4e42-9acf-b2a990b30812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the amount of data to set aside for final testing\n",
    "holdout_pct = 0.10\n",
    "nfolds = 5\n",
    "n_boost_rounds = 2000\n",
    "n_optimization_rounds = 20\n",
    "\n",
    "all_test_results = {}\n",
    "attribute_set_names = ['climate', '+land_cover', '+terrain', '+soil']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4790193-17a2-45e1-8f48-68b312fa3067",
   "metadata": {},
   "source": [
    "## Run XGBoost Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241de870-1599-437d-8fd8-497bec87f469",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_fname = f'Entropy_prediction_results.npy'\n",
    "test_results_fpath = os.path.join(results_folder, test_results_fname)\n",
    "if os.path.exists(test_results_fpath):\n",
    "    all_test_results = np.load(test_results_fpath, allow_pickle=True).item()\n",
    "else:\n",
    "    all_test_results = predict_entropy_from_attributes(df, holdout_pct, results_folder)\n",
    "    np.save(test_results_fpath, all_test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c649bac-4d5d-45eb-8dd0-ed7de779c60b",
   "metadata": {},
   "source": [
    "## View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e31877-0344-4876-8427-48ea26e5b117",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = []\n",
    "for b, set_dict in all_test_results.items():\n",
    "    test_rmse, test_mae = [], []\n",
    "    attribute_sets = list(set_dict.keys())\n",
    "\n",
    "    y1 = [set_dict[e]['test_rmse'] for e in attribute_sets]\n",
    "    y2 = [set_dict[e]['test_mae'] for e in attribute_sets]\n",
    "    \n",
    "    source = ColumnDataSource({'x': attribute_sets, 'y1': y1, 'y2': y2})\n",
    "    \n",
    "    title = f'{b} bits'\n",
    "    if len(plots) == 0:\n",
    "        fig = figure(title=title, x_range=attribute_sets)\n",
    "    else:\n",
    "        fig = figure(title=title, x_range=attribute_sets, y_range=plots[0].y_range)\n",
    "    fig.line('x', 'y1', legend_label='rmse', color='green', source=source, line_width=3)\n",
    "    fig.line('x', 'y2', legend_label='mae', color='dodgerblue', source=source, line_width=3)\n",
    "    fig.legend.background_fill_alpha = 0.6\n",
    "    fig.yaxis.axis_label = 'RMSE'\n",
    "    \n",
    "    result_df = pd.DataFrame({'set': attribute_sets, 'rmse': y1, 'mae': y2})\n",
    "    best_rmse_idx = result_df['rmse'].idxmin()\n",
    "    best_mae_idx = result_df['mae'].idxmin()\n",
    "    best_rmse_set = result_df.loc[best_rmse_idx, 'set']\n",
    "    best_mae_set = result_df.loc[best_mae_idx, 'set']\n",
    "    best_result = set_dict[best_rmse_set]['test_df']\n",
    "    \n",
    "    xx, yy = best_result['actual'], best_result['predicted']\n",
    "    slope, intercept, r, p, se = linregress(xx, yy)\n",
    "    \n",
    "    sfig = figure(title=f'Test: {b} bits best model {best_rmse_set} (N={len(best_result)})')\n",
    "    sfig.scatter(xx, yy, size=3, alpha=0.8)\n",
    "    xpred = np.linspace(min(xx), max(xx), 100)\n",
    "    ybf = [slope * e + intercept for e in xpred]\n",
    "    sfig.line(xpred, ybf, color='red', line_width=3, line_dash='dashed', legend_label=f'RÂ²={r**2:.2f}') \n",
    "    # plot a 1:1 line\n",
    "    sfig.line([min(yy), max(yy)], [min(yy), max(yy)], color='black', line_dash='dotted', \n",
    "              line_width=2, legend_label='1:1')\n",
    "    sfig.xaxis.axis_label = 'Actual H [bits/sample]'\n",
    "    sfig.yaxis.axis_label = 'Predicted H [bits/sample]'\n",
    "    sfig.legend.location = 'top_left'\n",
    "    \n",
    "    plots.append(fig)\n",
    "    plots.append(sfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65045b7c-1806-43f4-918a-88dbd12dc62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = gridplot(plots, ncols=2, width=350, height=300)\n",
    "show(layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57575461-13c6-482b-b39b-ae6d5cb1fd16",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "Model performance metrics can't be compared across different dictionary sizes because the distributions of the target variable are different, and the scale changes as a function of dictionary size.  However looking at the $R^2$ of the predicted vs. \"actual\" entropy plots (right column), it seems that the model works best at at bits, corresponding to a dictionary size of 1024 unique symbols (states).  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726a1db2-7b71-45e5-859b-fc3cbd7f0a87",
   "metadata": {},
   "source": [
    "## Citations\n",
    "\n",
    "```{bibliography}\n",
    ":filter: docname in docnames\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
