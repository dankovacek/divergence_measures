{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eec6f101-baba-407b-bbd0-da0b48b55d58",
   "metadata": {},
   "source": [
    "# Process Target Variables\n",
    "\n",
    "After updating the catchment attributes using revised catchment bounds from USGS and WSC where available, or delineating them from processed rasters where not available, the target variables are the last input data to be processed before we can train the gradient boosted decision tree (GBDT) models to take in attributes and predict the various target variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca15319a-251b-4963-8a52-c40154aae3e3",
   "metadata": {},
   "source": [
    "## Shannon entropy processing\n",
    "\n",
    "Compute the Shannon entropy of individual streamflow time series.  The Shannon entropy is given by: \n",
    "\n",
    "$$H(X) = \\sum_{i=1}^n P(x_i) \\log_2 P(x_i)$$\n",
    "\n",
    "The entropy is computed for various quantization bit depths (`bitrate` parameter, $n=2^{bitrate}$ in the above summation).  No prior is applied here.\n",
    "\n",
    "From the scipy.stats [docs](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.entropy.html):\n",
    ">*\"If messages consisting of sequences of symbols from a set are to be encoded and transmitted over a noiseless channel, then the Shannon entropy H(pk) gives a tight lower bound for the average number of units of information [bits] needed per symbol if the symbols occur with frequencies governed by the discrete distribution pk.\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c41fda-caf4-4e8c-8ff8-e3d4ded409f0",
   "metadata": {},
   "source": [
    "Let's run through an example computation to see the difference between 4, 6, and 8 bit quantization, how each represents the total measurement range, and how each quantization aligns with your own expectation of heteroscedastic rating curve uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf7cb74-1b3a-448d-be6e-50656934d17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "from scipy.stats import entropy\n",
    "import multiprocessing as mp\n",
    "import data_processing_functions as dpf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# visualize the catchment centroid locations\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.palettes import Colorblind, Sunset10\n",
    "output_notebook()\n",
    "\n",
    "BASE_DIR = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928ca57b-befb-434d-b298-2ff2ccf708ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_signal(df, b, label, stn):\n",
    "    df.dropna(subset=[stn], inplace=True)\n",
    "    # add a very small margin on the range to ensure the values are contained \n",
    "    # within the specified dictionary size because the right edge is closed\n",
    "    # by default and will return 2**b + 1 for values equal to the max\n",
    "    min_q, max_q = df[stn].min() - 1e-9, df[stn].max() + 1e-9\n",
    "    print(f'observed range: {min_q:.3f}-{max_q:.3f}')\n",
    "    assert min_q > 0\n",
    "    # use equal width bins in log10 space\n",
    "    log_edges = np.linspace(np.log10(min_q), np.log10(max_q), 2**b)\n",
    "    linear_edges = np.linspace(min_q, np.log10(max_q), 2**b)\n",
    "    edges = np.power(10, log_edges)\n",
    "\n",
    "    data = df[stn].values\n",
    "    sorted_data = np.sort(data)\n",
    "    ecdf_values = np.arange(1, len(sorted_data) + 1) / len(sorted_data)\n",
    "    pmf = dpf.interpolate_ecdf(edges, sorted_data, ecdf_values)\n",
    "    return pmf, linear_edges, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a9c7d2-7159-46a2-9bdf-e561930c9100",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stn = '05010500'\n",
    "test_df = dpf.get_timeseries_data(test_stn)\n",
    "\n",
    "n_years = len(test_df)/365\n",
    "\n",
    "test_fig = figure(title=f'Sample Distribution by Dictionary Size (Station ID {test_stn}, N=~{n_years:.1f} years record)',\n",
    "                 width=800, height=300)#, x_axis_type='log')\n",
    "n = 0\n",
    "bitrates_even = [4, 6, 8, 10, 12]\n",
    "for b in bitrates_even:\n",
    "    t0 = time()\n",
    "\n",
    "    normed_freqs, lin_space_edges, log_space_edges = quantize_signal(test_df, b, f'{b}_bits_quantized', test_stn)\n",
    "    \n",
    "    t1 = time()\n",
    "    H = entropy(normed_frequencies, base=2)\n",
    "    lin_bin_midpoints = (lin_space_edges[1:] + lin_space_edges[-1]) / 2\n",
    "    log_bin_midpoints = (log_space_edges[1:] + log_space_edges[-1]) / 2\n",
    "    bottoms = [0 for _ in normed_freqs]\n",
    "    test_fig.quad(left=log_space_edges[:-1], right=log_space_edges[1:], top=normed_freqs, bottom=bottoms, \n",
    "                  legend_label=f'{b} bits (H={H:.2f})', color=Sunset10[n], fill_alpha=0.5)\n",
    "    \n",
    "    test_fig.xaxis.axis_label = r'$$\\text{Flow} \\left[ m^3/s \\right]$$'\n",
    "    test_fig.yaxis.axis_label = r'P(X)'\n",
    "    test_fig.legend.location = 'top_right'\n",
    "    test_fig.legend.click_policy = 'hide'\n",
    "    n += 2\n",
    "    t2 = time()\n",
    "    print(f'{t1-t0:.3f}s to compute PMF, {t2-t1:.3f}s to compute entropy and plot')\n",
    "    \n",
    "test_fig.legend.background_fill_alpha = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ba60a9-461d-40b9-9b8a-0fa1143102e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(test_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f49e95e-c8e6-48dd-ad74-226926358051",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a new output filename \n",
    "attributes_filename = 'BCUB_watershed_attributes_updated.csv'\n",
    "attributes_fpath = os.path.join(os.getcwd(), 'data', attributes_filename)\n",
    "attr_df = pd.read_csv(attributes_fpath)\n",
    "attr_df.columns = [e.lower() for e in attr_df.columns]\n",
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2befeaa7-61ee-412e-98aa-9d37774e4221",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_stns = sorted(list(set(attr_df['official_id'].values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2f9bb2-02f0-4789-88e3-3ba472b410ce",
   "metadata": {},
   "source": [
    "## Compute the \"distortion\" of an assumed error distribution as a prior\n",
    "\n",
    "Rating curve uncertainty is a hard problem in hydrology.  Instead of treating daily flow observations as discrete measurements with the fixed (often overzealous) precision that it is published by governing agencies, we can assume some kind of basic error model and test how much the error model distorts the information in the distribution.  In other words, how much noise/uncertainty is added for any model error.  \n",
    "\n",
    "Below we'll test a range of uniform error distributions as models for the observations.  We'll take an example streamflow record, and we'll quantize it to a range of dictionary sizes in two ways:  \n",
    "1. **\"idealized observations\":** bin the observations as they are,\n",
    "2. **\"constant proportion error\"**: assume a uniform error on each observation equal to a constant proportion, and bin the observations by counting the fraction of the error interval covering each bin.  In other words, we'll count partial observations in proportion to how they overlap the binning intervals as opposed to counting a whole observation based on the interval alone.\n",
    "\n",
    "The quantization will take in a bitrate $b$, and it will divide and log-transform the measured interval $(\\log(x_\\text{min}),\\log(x_\\text{max}))$ into $2^b$ (log-spaced) bins.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3d5182-e940-4556-a8a1-3706124bd8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_uniform_bins(df, stn, bitrate):\n",
    "    n_bins = 2**bitrate - 2\n",
    "    # set the bin edges to be evenly spaced between the\n",
    "    # observed range of the proxy/donor series\n",
    "    # np.digitize will assign 0 for out-of-range values at left\n",
    "    # and n_bins + 1 for out-of-range values at right\n",
    "    log_bin_edges = np.linspace(\n",
    "        np.log10(df[stn].min()),\n",
    "        np.log10(df[stn].max()),\n",
    "        n_bins + 1,\n",
    "    ).flatten()\n",
    "    # convert back to linear space\n",
    "    bin_edges = [10**e for e in log_bin_edges]\n",
    "    return bin_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c7cda9-e204-4bda-8566-f59e4215c010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_error_to_observations(df, stn, bitrate=None, error=0.1):\n",
    "    min_q, max_q = df[stn].min() - 1e-9, df[stn].max() + 1e-9\n",
    "    assert min_q > 0\n",
    "    # use equal width bins in log10 space\n",
    "    bin_edges = compute_log_uniform_bins(df, stn, bitrate)\n",
    "    # df[f'{bitrate}_bits_quantized'] = np.digitize(df[stn], bin_edges)\n",
    "    fractional_obs_counts = dpf.error_adjusted_fractional_bin_counts(\n",
    "        df[stn], np.array(bin_edges), bitrate, error_factor=error\n",
    "    )\n",
    "    label = f'{stn}_{int(100*error)}_error'\n",
    "    count_df = pd.DataFrame(index=range(2**bitrate))\n",
    "    count_df[label] = 0\n",
    "    count_df[label] += fractional_obs_counts\n",
    "    count_df.fillna(0, inplace=True)\n",
    "    n_obs = np.nansum(count_df[label])\n",
    "    # normalize p_obs and p_sim\n",
    "    return count_df[label].values / n_obs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b54815e-3e59-4712-a405-20c6d594fa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_unadjusted_counts(df, stn, bitrate):\n",
    "    bin_edges = compute_log_uniform_bins(df, stn, bitrate)\n",
    "    label = f'{stn}_simple_{bitrate}bits'\n",
    "    df[label] = np.digitize(df[stn], bin_edges)\n",
    "    # print(df[[stn, f'{stn}_quantized_{bitrate}bits']].head(4))\n",
    "    # count the occurrences of each quantized value\n",
    "    # the \"simulated\" series is the proxy/donor series\n",
    "    # and the \"observed\" series is the target location\n",
    "    obs_count_df = df.groupby(label).count()\n",
    "    count_df = pd.DataFrame(index=range(2**bitrate))\n",
    "    count_df[label] = 0\n",
    "    count_df[label] += obs_count_df[stn]\n",
    "    count_df.fillna(0, inplace=True)\n",
    "    adjusted_p = count_df / obs_count_df[stn].sum()\n",
    "    return adjusted_p.values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bed0c3a-8f3d-4b9a-8289-3aca49a6188b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error_bias(inputs):\n",
    "    df, stn, b, err = inputs\n",
    "    t0 = time()\n",
    "    simple_frequencies = compute_unadjusted_counts(df, stn, b)\n",
    "    error_adjusted_frequencies = apply_error_to_observations(df, stn, bitrate=b, error=err)\n",
    "    # compute KL divergence between the simple and adjusted frequencies\n",
    "    # this represents the distortion due to the error model\n",
    "    mask = (simple_frequencies > 0) & (error_adjusted_frequencies > 0)\n",
    "    distortion = np.zeros_like(simple_frequencies)\n",
    "    distortion[mask] = simple_frequencies[mask] * np.log2(simple_frequencies[mask] / error_adjusted_frequencies[mask])\n",
    "    kld = sum(distortion)\n",
    "    return stn, kld, b, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b01490-1583-4b45-b16d-bd1523c6cbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "distortions = {}\n",
    "distortion_fig = figure(width=600, height=400, y_axis_type='log')\n",
    "error_models = [1e-12, 1e-4, 1e-3, 2.5e-3, 5e-3, 1e-2, 2.5e-2, 5e-2, 1e-1, 2e-1]\n",
    "stn_df = dpf.get_timeseries_data(test_stn)\n",
    "for b in range(3, 13):\n",
    "    distortions[b] = []\n",
    "    print(f'computing {b} bits')\n",
    "    for err in error_models:\n",
    "        t1 = time()\n",
    "        stn, kld, b, err = compute_error_bias((stn_df, test_stn, b, err))\n",
    "        distortions[b].append(kld)\n",
    "    \n",
    "    err_labels = [100*e for e in error_models]\n",
    "    distortion_fig.line(err_labels, distortions[b], line_width=2, line_color=Sunset10[n],\n",
    "                   legend_label=f'{b} bits')\n",
    "    n += 1\n",
    "\n",
    "distortion_fig.legend.location = 'top_left'\n",
    "distortion_fig.legend.click_policy = 'hide'\n",
    "distortion_fig.xaxis.axis_label = r'$$\\text{Error Model } [\\%]$$'\n",
    "distortion_fig.yaxis.axis_label = r'$$\\text{Error Bias } [\\text{bits}/\\text{sample}]$$'\n",
    "distortion_fig.add_layout(distortion_fig.legend[0], 'right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bdef0e-344b-467b-85f8-468d7fecbe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "distortion_fig = dpf.format_fig_fonts(distortion_fig)\n",
    "show(distortion_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d93268-8eac-48b9-8a59-33e720dcda39",
   "metadata": {},
   "source": [
    "### Compute the distortion on all samples\n",
    "\n",
    "Above we looked at one example.  There are 1325 in the dataset. Evaluate the distribution of distortion across the dataset based on a range of error models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247aaf1a-88a3-4587-bfde-8be532d8b0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcts = [2.5, 25, 50, 75, 98.5]\n",
    "dfigs = []\n",
    "distortions = {b: {} for b in bitrates_even}\n",
    "for b in bitrates_even:\n",
    "    distortions[b] = {e: [] for e in error_models}\n",
    "i = 0\n",
    "t0 = time()\n",
    "all_results = []\n",
    "n_stns = len(attr_df)\n",
    "error_model_bias_fname = 'data/error_model_distortion/error_model_distortion_test.csv'\n",
    "if not os.path.exists(error_model_distortion_fname):\n",
    "    for stn in attr_df['official_id'].values:\n",
    "        stn_df = dpf.get_timeseries_data(stn)\n",
    "        inputs = [\n",
    "            (stn_df, stn, b, err)\n",
    "            for b in bitrates_even\n",
    "            for err in error_models\n",
    "        ]\n",
    "        with mp.Pool() as pool:\n",
    "            results = pool.map(compute_error_bias, inputs)\n",
    "            rdf = pd.DataFrame(results, columns=['official_id', 'value', 'bitrate', 'err'])\n",
    "            all_results.append(rdf)\n",
    "        i += 1\n",
    "        if i % 50 == 0:\n",
    "            et = time() - t0\n",
    "            print(f'{i}/{n_stns} stns processed in {et/60:.1f}min')\n",
    "        # if i % 100 == 0:\n",
    "        #     break\n",
    "    results_df = pd.concat(all_results, axis=0)\n",
    "    results_df.to_csv(error_model_bias_fname, index=False)\n",
    "else:\n",
    "    results_df = pd.read_csv(error_model_bias_fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6c83a3-b63f-41af-baaa-ed4601fe328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bound_dict = {}\n",
    "for b in bitrates_even:\n",
    "    if b in [3, 5, 7, 9, 11]:\n",
    "        continue\n",
    "    err_bounds = []\n",
    "    for err in error_models:\n",
    "        # get all values for the bitrate and error model\n",
    "        data = results_df[(results_df['bitrate'] == b) & (results_df['err'] == err)].copy()\n",
    "        # get percentiles of the sample\n",
    "        err_bounds += [np.percentile(data['value'].values, pcts)]\n",
    "    bound_dict[b] = pd.DataFrame(err_bounds, columns=pcts)\n",
    "    bound_dict[b]['err'] = error_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5094db3e-3c21-42f4-ad76-ad420b1fc286",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfigs = []\n",
    "for b in range(3, 13):\n",
    "    if b in [3, 5, 7, 9, 11]:\n",
    "        continue\n",
    "    dfig = figure(width=500, height=400, y_axis_type='log')\n",
    "    if len(dfigs) > 0:\n",
    "        dfig = figure(width=500, height=400, y_range=dfigs[-1].y_range,\n",
    "                     y_axis_type='log')\n",
    "\n",
    "    err_labels = [100*e for e in error_models]\n",
    "    data = bound_dict[b].copy()\n",
    "    error = np.round(100*data['err'], 0)\n",
    "    dfig.varea(data['err'], y1=data[2.5], y2=data[98.5], \n",
    "               color='grey', fill_alpha=0.4, legend_label='95% CI')\n",
    "    dfig.varea(data['err'], y1=data[25], y2=data[75], \n",
    "               color='black', fill_alpha=0.4, legend_label='IQR')\n",
    "    dfig.line(data['err'], data[50], line_width=2, line_color='red',\n",
    "                       legend_label=f'Median')\n",
    "    n += 1\n",
    "    dfig.legend.location = 'top_left'\n",
    "    dfig.xaxis.axis_label = r'$$\\text{RC Error Model} [\\%]$$'\n",
    "    \n",
    "    if (len(dfigs) == 0) | (len(dfigs) == 3):\n",
    "        dfig.legend.background_fill_alpha = 0.5\n",
    "        dfig.yaxis.axis_label = r'$$\\text{Distortion } [\\text{bps}]$$'\n",
    "    if len(dfigs) > 0:\n",
    "        dfig.legend.visible = False\n",
    "    dfig = dpf.format_fig_fonts(dfig)\n",
    "    dfigs.append(dfig)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f76a34-4730-4ef8-ac02-440ef5727609",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = gridplot(dfigs, ncols=3, width=400, height=350)\n",
    "show(layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0095bd89-dc23-4d99-a49c-af8a3710cc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the bitrate dictates the number of quantization levels = 2**b, i.e. 4 bits = 16 levels\n",
    "quant_labels = []\n",
    "filename = 'BCUB_watershed_attributes_updated.csv'\n",
    "bitrates = list(range(3, 13))\n",
    "entropy_fpath = os.path.join(BASE_DIR, 'data', 'processed_divergence_inputs', attributes_filename)\n",
    "if not os.path.exists(entropy_fpath):\n",
    "    for bitrate in bitrates:\n",
    "        label = f'H_{bitrate}_bits'\n",
    "        print(f'Processing {bitrate} bit entropy')\n",
    "        df[label] = df.apply(lambda row: dpf.compute_observed_series_entropy(row, bitrate), axis=1) \n",
    "        quant_labels.append(label)\n",
    "    # save the results\n",
    "    df.to_csv(entropy_fpath, index=False)\n",
    "else:\n",
    "    df = pd.read_csv(entropy_fpath)\n",
    "    quant_labels = [e for e in df.columns if e.startswith('H_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cee928-210f-4637-ba56-e6a37883073a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the CDFs of entropy by quantization\n",
    "fig = figure(width=600, height=350, x_axis_label=r'$$H(X)$$', y_axis_label=r'$$P(H)$$')\n",
    "n = 0\n",
    "for l in quant_labels:\n",
    "    x, y = dpf.compute_cdf(df[l])\n",
    "    fig.line(x, y, legend_label=' '.join(l.split('_')[1:]), line_width=2, color=Sunset10[n])\n",
    "    n += 1\n",
    "fig.legend.location = 'top_left'\n",
    "fig.legend.background_fill_alpha = 0.5\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f18fb7-53ef-462c-a82d-3218e6f4869d",
   "metadata": {},
   "source": [
    "## Parametric Distribution Fitting\n",
    "\n",
    "For each timeseries, generate the sufficient statistics based on an asumed parametric distribution.  \n",
    "\n",
    ">*Sufficient statistics are a set of scalar (or vector) valued summaries that, combined with a statistical model, contain all the information needed to estimate the parameters of a probability distribution.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91a6e20-f505-4b9e-bf25-b9432b2ce388",
   "metadata": {},
   "source": [
    "## Pairwise f-divergence processing\n",
    "\n",
    "There are roughly 900K pairings.  To speed up the processing and avoid losing progress, we process these in parallel in batches and save the results intermittently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768ce523-2c3e-4d57-a008-b9a45e724f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the attributes file with catchment geometries\n",
    "geom_file = 'BCUB_watershed_attributes_updated.geojson'\n",
    "bcub_gdf = gpd.read_file(os.path.join(os.getcwd(), 'data', geom_file))\n",
    "bcub_gdf.columns = [c.lower() for c in bcub_gdf.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48d7fe9-2918-4651-8990-2bac56cdd845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure that all stations appear in both datasets\n",
    "gdf_ids = list(set(bcub_gdf['official_id'].values))\n",
    "df_ids = list(set(df['official_id'].values))\n",
    "diff_ids = np.setdiff1d(gdf_ids, df_ids)\n",
    "assert len(diff_ids) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b919715e-91cd-4e99-846a-514036fa69b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "unique_stations = list(set(df['official_id'].values))\n",
    "# generate all combinations of pairs of station ids\n",
    "id_pairs = list(itertools.combinations(unique_stations, 2))\n",
    "print(f' There are {len(id_pairs)} unique pairings in the dataset')\n",
    "# shuffle the pairs to make testing smaller batches more robust\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(id_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf9924d-9b0e-4c65-ae76-9228955ecfd1",
   "metadata": {},
   "source": [
    "Review, organize, and separate the attribute and metadata columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65949aea-dff3-4549-85f0-f0775655d917",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_cols = [\n",
    "    'drainage_area_km2', 'elevation_m', 'slope_deg', 'aspect_deg', \n",
    "    'land_use_forest_frac_2010','land_use_grass_frac_2010', 'land_use_wetland_frac_2010',\n",
    "    'land_use_water_frac_2010', 'land_use_urban_frac_2010', 'land_use_shrubs_frac_2010', \n",
    "    'land_use_crops_frac_2010', 'land_use_snow_ice_frac_2010', 'logk_ice_x100', 'porosity_x100'\n",
    "]\n",
    "\n",
    "climate_cols = [\n",
    "    'tmax', 'tmin', 'prcp', 'srad', 'swe', 'vp', \n",
    "    'high_prcp_freq', 'low_prcp_freq', 'high_prcp_duration', 'low_prcp_duration',\n",
    "]\n",
    "\n",
    "flag_cols = ['flag_shape_extraction', 'flag_terrain_extraction', 'flag_subsoil_extraction', 'flag_gsim_boundaries', 'flag_artificial_boundaries', 'flag_land_use_extraction']\n",
    "metadata_cols = [e for e in df.columns if e not in climate_cols + attr_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94da8cba-f12e-418d-aa7a-57b95d408832",
   "metadata": {},
   "source": [
    "### Define input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41d74c8-47f1-48d0-967f-42593ba088d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a revision date for the results output file\n",
    "revision_date = '20241023'\n",
    "\n",
    "# how many pairs to compute in each batch\n",
    "batch_size = 5000\n",
    "batch_size = 10\n",
    "\n",
    "# # what percentage of 365 observations in a year counts as a \"complete\" year\n",
    "# completeness_threshold = 0.9\n",
    "# min_observations = 365 * 0.9\n",
    "\n",
    "# station pairs with less than min_years concurrent years of data are excluded (for concurrent analysis),\n",
    "# stations with less than min_years are excluded (for non-concurrent analysis),\n",
    "min_years = 1 #[2, 3, 4, 5, 10]\n",
    "\n",
    "# a prior is applied to q in the form of a uniform array of 10**c pseudo-counts \"c\"\n",
    "# this prior is used to test the effect of the choice of prior on the model\n",
    "pseudo_counts = [-5, -4, -3, -2, -1, -0.5, -0.2, -0.1, 0, 0.1, 0.2, 0.5, 1, 2, 3, 4, 5]\n",
    "\n",
    "# set the number of quantization levels to test, equal to 2^bitrate\n",
    "bitrates = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227acc48-47a5-45cd-a148-d28ca53ac234",
   "metadata": {},
   "source": [
    "## Process the data \n",
    "\n",
    "\n",
    "```{note}\n",
    "This step is very time consuming, you can skip by downloading the processed files as described at the [top of the page](https://dankovacek.github.io/divergence_measures/notebooks/1_data.html)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e244e35-4c54-4ec4-8882-5f6d09b490ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_batch_generator(df, id_pairs_filtered, bitrate, error_df,\n",
    "                          min_years, use_partial_counts, attr_cols, \n",
    "                          climate_cols, pseudo_counts):\n",
    "    \n",
    "    # Preload all records into a dictionary for fast lookup\n",
    "    records_dict = bcub_gdf.copy().set_index('official_id').to_dict(orient='index')\n",
    "\n",
    "    unique_ids = list(set(id_pairs_filtered.flatten()))\n",
    "    record_ids = bcub_gdf['official_id'].values\n",
    "\n",
    "    foo = np.setdiff1d(unique_ids, record_ids)\n",
    "    \n",
    "    batch_inputs = []\n",
    "    for proxy, target in id_pairs_filtered:\n",
    "        \n",
    "        proxy_dict = records_dict.get(proxy, {})\n",
    "        target_dict = records_dict.get(target, {})\n",
    "\n",
    "        proxy_dict['official_id'] = proxy\n",
    "        target_dict['official_id'] = target\n",
    "\n",
    "        assert 'geometry' in proxy_dict.keys(), proxy_dict.keys()\n",
    "        assert 'geometry' in target_dict.keys(), target_dict.keys()\n",
    "        \n",
    "        batch = [\n",
    "            proxy_dict, target_dict, bitrate, \n",
    "            error_df, min_years, attr_cols, climate_cols, pseudo_counts\n",
    "        ]\n",
    "        batch_inputs.append(batch)\n",
    "    return batch_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f237d66-6881-47cf-b44f-dc174a335411",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dir = os.path.join(os.getcwd(), 'data/', 'temp')\n",
    "if not os.path.exists(temp_dir):\n",
    "    os.makedirs(temp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73677607-8798-4e6c-b63d-29d1d74e6710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the distortion error dataframe\n",
    "error_model_distortion_fname = 'data/error_model_distortion/error_model_distortion_test.csv'\n",
    "error_model_df = pd.read_csv(error_model_distortion_fname)\n",
    "error_model_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e86d2fa-d49d-4682-bdd2-17e0bc283c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_posterior_Q_probabilities(\n",
    "    simple_count_df, partial_count_df, target, bitrate, pseudo_counts, concurrent_data, bin_edges, p_errors\n",
    "):\n",
    "    n_obs = np.nansum(simple_count_df[target.obs_label])\n",
    "    n_sim = np.nansum(simple_count_df[target.sim_label])\n",
    "\n",
    "    if concurrent_data:\n",
    "        assert round(n_obs, 0) == round(n_sim, 0), f\"Number of observations and simulations do not match. n_obs={n_obs}, n_sim={n_sim}\"\n",
    "\n",
    "    # normalize p_obs and p_sim\n",
    "    p_obs = count_df[target.obs_label].values / n_obs\n",
    "    p_sim = count_df[target.sim_label].values / n_sim\n",
    "    assert round(np.sum(p_sim), 2) == 1.0, \"p_sim does not sum to 1.0\"\n",
    "\n",
    "    p_df = pd.DataFrame()\n",
    "    p_df['p_simple_counts'] = p_obs\n",
    "    p_df['p_partial_counts'] = partial_count_df[target.obs_label].values / n_obs\n",
    "\n",
    "    # create a dataframe to store the posterior Q after assuming different priors\n",
    "    q_df = pd.DataFrame()\n",
    "    # first save Q, the model (simulated) distribution\n",
    "    q_df[\"q_sim_no_prior\"] = p_sim\n",
    "    \n",
    "\n",
    "    uniform_p = [1.0 / 2.0**bitrate for _ in range(2**bitrate)]\n",
    "    q_df[\"q_uniform\"] = test_probability_distribution_sums_to_one(uniform_p, bitrate)\n",
    "\n",
    "    # compute the posterior probabilities based on\n",
    "    # a wide range of priors to test sensitivity\n",
    "    for pseudo_counts in pseudo_counts:\n",
    "        adjusted_counts = [x + 10**pseudo_counts for x in count_df[target.sim_label]]\n",
    "        tot_adjusted_counts = np.nansum(adjusted_counts)\n",
    "        q_df[f\"q_post_{pseudo_counts}R\"] = adjusted_counts / tot_adjusted_counts\n",
    "        assert (\n",
    "            np.round(q_df[f\"q_post_{pseudo_counts}R\"].sum(), 5) == 1\n",
    "        ), \"Posterior probabilities do not sum to 1.\"\n",
    "\n",
    "    return p_obs, q_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c5ef26-8961-49b7-86ed-de4648c1ffc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_probabilities(\n",
    "    df, proxy, target, bitrate, concurrent_data, pseudo_counts, p_errors\n",
    "):\n",
    "    # compute the bin edges based on equal width in log space\n",
    "    bin_edges = dpf.uniform_log_bins(df, proxy, bitrate)\n",
    "\n",
    "    # if partial_counts == False:\n",
    "        # computes the observed P and simulation Q distribution probabilities\n",
    "        # as dicts by bin number, probability key-value pairs\n",
    "        # test a wide range of uniform priors via pseudo counts\n",
    "    simple_count_df = dpf.compute_unadjusted_counts(\n",
    "        df, target, bin_edges, bitrate, concurrent_data\n",
    "    )\n",
    "    # add a uniformly distributed error to the observed data\n",
    "    # and compute probabilities from partial observation counts\n",
    "    # where counts are divided based on the proportion of the bin\n",
    "    # that the measurement error falls within\n",
    "    t0 = time()\n",
    "    fractional_obs_counts = dpf.error_adjusted_fractional_bin_counts(\n",
    "        df[target.obs_label], np.array(bin_edges), bitrate, error_factor=0.1\n",
    "    )\n",
    "    fractional_sim_counts = dpf.error_adjusted_fractional_bin_counts(\n",
    "        df[target.sim_label], np.array(bin_edges), bitrate, error_factor=0.1\n",
    "    )\n",
    "    t1 = time()\n",
    "    # print(f' {t1-t0:.2f}s to process fractional bin counts')\n",
    "\n",
    "    partial_count_df = pd.DataFrame(index=range(2**bitrate))\n",
    "    partial_count_df[target.obs_label] = 0\n",
    "    partial_count_df[target.sim_label] = 0\n",
    "    partial_count_df[target.obs_label] += fractional_obs_counts\n",
    "    partial_count_df[target.sim_label] += fractional_sim_counts\n",
    "    partial_count_df.fillna(0, inplace=True)\n",
    "\n",
    "    # p_obs is the P, the observed target binned using the \n",
    "    # observed range of the model to \"optimize\" the model for P\n",
    "    # this is because DKL is the extra bits per sample caused by\n",
    "    # encoding a set of observations on a sub-optimal model P\n",
    "    p_obs, p_sim = compute_posterior_Q_probabilities(\n",
    "        simple_count_df, partial_count_df, target, bitrate, pseudo_counts, concurrent_data, bin_edges, p_errors,\n",
    "    )\n",
    "    \n",
    "    # the prior adds some amount of noise to the distribution\n",
    "    # we should compute this noise (via the KL divergence \n",
    "    # between the model q and the posterior r\n",
    "    \n",
    "    # set a flag where the simulation counts zero in any state\n",
    "    # where the a posteriori observation counts are > 0.\n",
    "    # it's these cases where the prior should have the greatest \n",
    "    # influence on the KL divergence.\n",
    "    underspecified_flag = (\n",
    "        (count_df[f'{target.official_id}_sim'] == 0) & \n",
    "        (count_df[target.official_id] > 0)\n",
    "    ).any()\n",
    "    \n",
    "    return p_obs, p_sim, bin_edges, underspecified_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ac41cd-0502-469c-9ca5-b10eb3eb5659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_divergences(result, p_obs, p_sim, bin_edges, bitrate, concurrent_data):\n",
    "    \n",
    "    dkl_by_prior = dpf.process_KL_divergence(p_obs, p_sim, bitrate, concurrent_data)\n",
    "\n",
    "    p = p_obs\n",
    "    q = p_sim[\"q_sim_no_prior\"].values\n",
    "    q_uniform = p_sim[\"q_uniform\"].values\n",
    "\n",
    "    tvd_result = dpf.compute_tvd(p, q, q_uniform, concurrent_data)\n",
    "    wd_result = dpf.compute_wasserstein_distance(\n",
    "        bin_edges, p, q, q_uniform, concurrent_data\n",
    "    )\n",
    "\n",
    "    result.update(tvd_result)\n",
    "    result.update(wd_result)\n",
    "    result.update(dkl_by_prior.to_dict())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f33b7e-1990-4fef-9478-8a6bb31a98bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_KL_divergence(p_obs, p_sim, bitrate, concurrent_data):\n",
    "    # dkl_df = uf.compute_kl_divergence(p_obs, p_sim, bitrate, concurrent_data)\n",
    "    df = pd.DataFrame()\n",
    "    df[\"bin\"] = range(1, 2**bitrate + 1)\n",
    "    df.set_index(\"bin\", inplace=True)\n",
    "\n",
    "    for c in p_sim.columns:\n",
    "        if c == \"q_sim_no_prior\":\n",
    "            continue\n",
    "\n",
    "        # explicitly set data types before vectorization\n",
    "        p = np.array(p_obs, dtype=np.float64)\n",
    "        q = np.array(p_sim[\"q_sim_no_prior\"].values, dtype=np.float64)\n",
    "        r = np.array(p_sim[c].values, dtype=np.float64) # the posterior\n",
    "        \n",
    "        # Raise error if any r[i] == 0, as log(p/r) is undefined for those cases\n",
    "        if np.any(r == 0):\n",
    "            raise ValueError(\"Posterior R contains zero entries, which is not allowed.\")\n",
    "\n",
    "        # ensure that the probabilities sum to 1\n",
    "        check_distribution(p, r, c)\n",
    "\n",
    "        label = \"dkl_nonconcurrent_\" + \"_\".join(c.split(\"_\")[1:])        \n",
    "        if concurrent_data is True:\n",
    "            label = \"dkl_concurrent_\" + \"_\".join(c.split(\"_\")[1:])\n",
    "\n",
    "        # compute the distortion due to the prior assumed on Q\n",
    "        mask = (p > 0) & (r > 0)\n",
    "        kld_array = np.zeros_like(p)\n",
    "        kld_array[mask] = p[mask] * np.log2(p[mask] / r[mask])\n",
    "        df[label] = kld_array\n",
    "            \n",
    "        # compute DKL(Q||R), or the distortion of Q \n",
    "        # due to the assumed prior\n",
    "        mask = (q > 0) & (r > 0)\n",
    "        distortion = np.zeros_like(q)\n",
    "        distortion[mask] = q[mask] * np.log2(q[mask] / r[mask])\n",
    "        label = \"dkl_prior_distortion_\" + \"_\".join(c.split(\"_\")[1:])\n",
    "        df[label] = distortion\n",
    "\n",
    "    sum_dkl = df.sum()\n",
    "\n",
    "    if any(sum_dkl.values) <= 0:\n",
    "        print(f\"negative or zero dkl\")\n",
    "        print(sum_dkl.values)\n",
    "\n",
    "    return sum_dkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed14691-9d3e-4a5e-989f-3cc33136a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_divergences(result, p_obs, p_sim, bin_edges, bitrate, concurrent_data):\n",
    "    dkl_by_prior = process_KL_divergence(p_obs, p_sim, bitrate, concurrent_data)\n",
    "\n",
    "    p = p_obs\n",
    "    q = p_sim[\"q_sim_no_prior\"].values\n",
    "    q_uniform = p_sim[\"q_uniform\"].values\n",
    "\n",
    "    tvd_result = compute_tvd(p, q, q_uniform, concurrent_data)\n",
    "    wd_result = compute_wasserstein_distance(\n",
    "        bin_edges, p, q, q_uniform, concurrent_data\n",
    "    )\n",
    "\n",
    "    result.update(tvd_result)\n",
    "    result.update(wd_result)\n",
    "    result.update(dkl_by_prior.to_dict())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a77bc11-73c7-4559-a928-820b4d6b6544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(inputs):    \n",
    "    (\n",
    "        proxy,\n",
    "        target,\n",
    "        bitrate,\n",
    "        error_df,\n",
    "        min_concurrent_years,\n",
    "        attr_cols,\n",
    "        climate_cols,\n",
    "        pseudo_counts,\n",
    "    ) = inputs\n",
    "\n",
    "    proxy_id, target_id = proxy['official_id'], target['official_id']\n",
    "    bitrate = int(bitrate)\n",
    "\n",
    "    # create a result dict object for tracking results of the batch comparison\n",
    "    result = {\n",
    "        \"proxy\": proxy_id,\n",
    "        \"target\": target_id,\n",
    "        \"bitrate\": bitrate,\n",
    "        \"min_concurrent_years\": min_concurrent_years,\n",
    "    }\n",
    "\n",
    "    station_info = {\"proxy\": proxy, \"target\": target}\n",
    "\n",
    "    # check if the polygons are nested\n",
    "    result[\"nested_catchments\"] = dpf.check_if_nested(\n",
    "        proxy, target\n",
    "    )\n",
    "\n",
    "    # for stn in pair:\n",
    "    proxy = dpf.Station(station_info[\"proxy\"], bitrate)\n",
    "    target = dpf.Station(station_info[\"target\"], bitrate)\n",
    "\n",
    "    # compute spatial distance\n",
    "    p1, p2 = (\n",
    "        station_info[\"proxy\"][\"geometry\"].centroid,\n",
    "        station_info[\"target\"][\"geometry\"].centroid,\n",
    "    )\n",
    "    # compute the distance between catchment centroids (km)\n",
    "    centroid_distance = p1.distance(p2) / 1000\n",
    "    result[\"centroid_distance\"] = round(centroid_distance, 2)\n",
    "    if centroid_distance > 1000:\n",
    "        return None\n",
    "\n",
    "    if np.isnan(target.drainage_area_km2):\n",
    "        raise ValueError(f\"No drainage area for {target_id}\")\n",
    "    if np.isnan(proxy.drainage_area_km2):\n",
    "        raise ValueError(f\"No drainage area for {proxy_id}\")\n",
    "\n",
    "    # Retrieve the data for both stations\n",
    "    # this is all data, including non-concurrent\n",
    "    adf = dpf.retrieve_nonconcurrent_data(proxy_id, target_id)\n",
    "\n",
    "    assert ~adf.empty, \"No data returned.\"\n",
    "\n",
    "    for stn in [proxy, target]:\n",
    "        adf = dpf.transform_and_jitter(adf, stn)\n",
    "\n",
    "    # simulate flow at the target based on equal unit area runoff scaling\n",
    "    adf[target.sim_label] = adf[proxy.id] * (\n",
    "        target.drainage_area_km2 / proxy.drainage_area_km2\n",
    "    )\n",
    "\n",
    "    # filter for the concurrent data\n",
    "    df = adf.copy().dropna(subset=[proxy_id, target_id], how=\"any\")\n",
    "    result[\"num_concurrent_obs\"] = len(df)\n",
    "    \n",
    "    if df.empty:\n",
    "        num_complete_concurrent_years = 0\n",
    "    else:\n",
    "        df.reset_index(inplace=True)\n",
    "        num_complete_concurrent_years = dpf.count_complete_years(df, 'time', proxy_id)\n",
    "        \n",
    "    counts = df[[proxy_id, target_id]].count(axis=0)\n",
    "    counts = adf.count(axis=0)\n",
    "    proxy.n_obs, target.n_obs = counts[proxy_id], counts[target_id]\n",
    "    result[f\"proxy_n_obs\"] = proxy.n_obs\n",
    "    result[f\"target_n_obs\"] = target.n_obs\n",
    "    result[f\"proxy_frac_concurrent\"] = len(df) / proxy.n_obs\n",
    "    result[f\"target_frac_concurrent\"] = len(df) / target.n_obs\n",
    "\n",
    "    if (counts[proxy_id] == 0) or (counts[target_id] == 0):\n",
    "        print(f\"   Zero observations.  Skipping.\")\n",
    "        return None\n",
    "\n",
    "    # for each of the error models, look up the model error distortion\n",
    "    # for the proxy (distortion of P) and add it to the results\n",
    "    p_errors = error_df[error_df['official_id'] == proxy.official_id]\n",
    "\n",
    "    # process the PMFs and divergences for concurrent data\n",
    "    # using a range of uniform priors via pseudo counts\n",
    "    if num_complete_concurrent_years > min_concurrent_years:\n",
    "        # compute coefficient of determination\n",
    "        result[\"cod\"] = dpf.compute_cod(df, proxy, target)\n",
    "\n",
    "        # compute Nash-Sutcliffe efficiency\n",
    "        result[\"nse\"] = dpf.compute_nse(df, proxy, target)\n",
    "\n",
    "        # compute the Kling-Gupta efficiency\n",
    "        result[\"kge\"] = dpf.compute_kge(df, proxy, target)\n",
    "\n",
    "        # df is concurrent data, so the results\n",
    "        # are updating concurrent data here\n",
    "        # df, proxy, target, bitrate, concurrent_data, partial_counts, pseudo_counts\n",
    "        concurrent_data = True\n",
    "        p_obs, p_sim, bin_edges, underspecified_flag = process_probabilities(\n",
    "            df, proxy, target, bitrate, concurrent_data, pseudo_counts, p_errors\n",
    "        )\n",
    "    if (target.n_obs > 365 * 0.9) & (proxy.n_obs > 365 * 0.9):\n",
    "        # adf is all data (includes non-concurrent), so the results\n",
    "        # are updated if both series meet the minimum length\n",
    "        concurrent_data = False\n",
    "        p_obs, p_sim, bin_edges, underspecified_flag = process_probabilities(\n",
    "            adf, proxy, target, bitrate, concurrent_data, pseudo_counts, p_errors\n",
    "        )\n",
    "        \n",
    "    result = dpf.process_divergences(\n",
    "        result, p_obs, p_sim, bin_edges, bitrate, concurrent_data\n",
    "    )\n",
    "    result['underspecified_model_flag'] = underspecified_flag\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c0987c-0b4a-4726-9498-93e626d52995",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the 'process' variable is here so jupyter doesn't go computing \n",
    "# a million rows per iteration when the book is built for pushing to github pages.\n",
    "reordered_bitrates = [4, 6, 8, 10, 12, 3, 5, 7, 9, 11]\n",
    "process = True\n",
    "if process: \n",
    "    for bitrate in reordered_bitrates:\n",
    "        print(f'Processing pairs at {bitrate} bits quantization (partial counts={partial_counts})')\n",
    "        results_fname = f'KL_results_{bitrate}bits_{revision_date}.csv'\n",
    "        # if partial_counts == True:\n",
    "        #     results_fname = results_fname.replace('.csv', '_partial_counts.csv')\n",
    "\n",
    "        out_fpath = os.path.join('data/', 'processed_divergence_inputs', results_fname)\n",
    "        if os.path.exists(out_fpath):\n",
    "            continue\n",
    "\n",
    "        n_batches = max(len(id_pairs) // batch_size, 1)\n",
    "        batches = np.array_split(np.array(id_pairs, dtype=object), n_batches)\n",
    "        n_pairs = len(id_pairs)\n",
    "        print(\n",
    "            f\"    Processing {n_pairs} pairs in {n_batches} batches at {bitrate} bits\"\n",
    "        )\n",
    "        batch_no = 1\n",
    "        batch_files = []\n",
    "        t0 = time()\n",
    "        error_df = error_model_df[error_model_df['bitrate'] == bitrate].copy()\n",
    "        for batch_ids in batches:\n",
    "            print(f'Starting batch {batch_no}/{len(batches)} processing.')\n",
    "            batch_fname = results_fname.replace('.csv', f'_batch_{batch_no:03d}.csv')\n",
    "            batch_output_fpath = os.path.join(temp_dir, batch_fname)\n",
    "            if os.path.exists(batch_output_fpath):\n",
    "                batch_files.append(batch_output_fpath)\n",
    "                batch_no += 1\n",
    "                continue\n",
    "            \n",
    "            # define the input array for multiprocessing\n",
    "            inputs = input_batch_generator(bcub_gdf, batch_ids, bitrate, error_df,\n",
    "                     min_years, partial_counts, attr_cols, climate_cols, pseudo_counts)\n",
    "\n",
    "            with mp.Pool(1) as pool:\n",
    "                results = pool.map(process_batch, inputs)\n",
    "                results = [r for r in results if r is not None]\n",
    "\n",
    "            batch_result = pd.DataFrame(results)\n",
    "            print(batch_result)\n",
    "            print(asdf)\n",
    "            if batch_result.empty:\n",
    "                print('Empty batch.  Skipping')\n",
    "            else:\n",
    "                batch_result.to_csv(batch_output_fpath, index=False)\n",
    "                print(f\"    Saved {len(batch_result)} new results to file.\")\n",
    "            \n",
    "            batch_files.append(batch_output_fpath)\n",
    "            t2 = time()\n",
    "            print(f'    Processed {len(batch_ids)} pairs at ({bitrate} bits) in {t2 - t0:.1f} seconds')\n",
    "            batch_no += 1\n",
    "            \n",
    "        print(f'    Concatenating {len(batch_files)} batch files.')\n",
    "        if len(batch_files) > 0:\n",
    "            all_results = pd.concat([pd.read_csv(f, engine='pyarrow') for f in batch_files], axis=0)\n",
    "            all_results.to_csv(out_fpath, index=False)\n",
    "            if os.path.exists(out_fpath):\n",
    "                for f in batch_files:\n",
    "                    os.remove(f)\n",
    "            print(f'    Wrote {len(all_results)} results to {out_fpath}')\n",
    "        else:\n",
    "            print('    No new results to write to file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe20ec95-81ca-4e7c-8a6c-12fc022cd25e",
   "metadata": {},
   "source": [
    "## Compare Parametric vs. Nonparametric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269281d5-ea54-4995-aa37-b146324b8df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 10\n",
    "rdate = '20241025'\n",
    "\n",
    "pfile = f'KL_parametric_fits_{b}bits_{rdate}.csv'\n",
    "out_fpath = os.path.join('data/', 'parametric_divergence_test', pfile)\n",
    "param_df = pd.read_csv(out_fpath)\n",
    "\n",
    "rdate = '20241016'\n",
    "npfile = f'KL_results_{b}bits_{rdate}.csv'\n",
    "out_fpath = os.path.join('data/', 'processed_divergence_inputs', npfile)\n",
    "np_df = pd.read_csv(out_fpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a2f692-4838-49b7-9691-da554dd158bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_df_sorted = param_df.sort_values(['proxy', 'target']).reset_index(drop=True)\n",
    "np_df_sorted = np_df.sort_values(['proxy', 'target']).reset_index(drop=True)\n",
    "# Compare row-by-row to ensure the pairings are identical\n",
    "if param_df_sorted[['proxy', 'target']].equals(np_df_sorted[['proxy', 'target']]):\n",
    "    print(\"All pairings match after sorting!\")\n",
    "else:\n",
    "    print(\"Mismatch(es) found in pairings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379d9be0-e416-4e8b-aa24-88a2f8607a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Find mismatched rows if needed\n",
    "# Optional: Find mismatched rows\n",
    "mismatches = param_df_sorted[~param_df_sorted[['proxy', 'target']].apply(tuple, axis=1)\n",
    "                         .isin(np_df_sorted[['proxy', 'target']].apply(tuple, axis=1))]\n",
    "\n",
    "if not mismatches.empty:\n",
    "    print(\"Mismatched rows:\")\n",
    "    print(len(mismatches))\n",
    "\n",
    "# Perform an inner join to find common rows based on (c1, c2)\n",
    "common_rows = pd.merge(param_df_sorted, np_df_sorted, on=['proxy', 'target'], how='inner', suffixes=('_param', '_np'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac2015b-f146-49ce-bb7a-aac42c88ff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcts = np.linspace(0, 100, 200)\n",
    "comp_df = pd.DataFrame()\n",
    "comp_df['pcts'] = pcts / 100\n",
    "comp_cols = [c for c in np_df.columns if c.startswith('dkl_concurrent_post')]\n",
    "for c in comp_cols:\n",
    "    prior = c.split('_')[-1].split('R')[0]\n",
    "    data = common_rows[[c, 'dkl_nonconcurrent_sim_lognorm_cdf']].copy()\n",
    "    data.dropna(how='any', inplace=True)\n",
    "    ratios = data['dkl_nonconcurrent_sim_lognorm_cdf'] / data[c] \n",
    "    ratios = ratios.clip(lower=0, upper=100)\n",
    "    comp_df[f'lognorm_vs_{b}bit_{prior}_np'] = np.percentile(ratios.values, pcts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13e8fe2-3484-498e-91f8-021451e28cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.palettes import Category20\n",
    "\n",
    "pal = Category20[17]\n",
    "\n",
    "ratio_cdf = figure(title=f'{b} bits', width=700, height=400)#, y_axis_type='log')\n",
    "stn_df = dpf.get_timeseries_data(test_stn)\n",
    "n = 0\n",
    "for c in comp_cols:\n",
    "    prior = c.split('_')[-1].split('R')[0]\n",
    "    ratio_cdf.line(comp_df[f'lognorm_vs_{b}bit_{prior}_np'], comp_df['pcts'], line_width=2, line_color=pal[n],\n",
    "                   legend_label=f'10^{prior}')\n",
    "    n += 1\n",
    "ratio_cdf.legend.ncols = 2\n",
    "ratio_cdf.legend.click_policy='hide'\n",
    "ratio_cdf.xaxis.axis_label = r'$$ D_\\text{KL} \\text{ ratio}\\text{ lognorm} / \\text{nonparametric fits}$$'\n",
    "ratio_cdf.yaxis.axis_label = r'$$Pr(x \\leq X)$$'\n",
    "ratio_cdf.add_layout(ratio_cdf.legend[0], 'right')\n",
    "ratio_cdf = dpf.format_fig_fonts(ratio_cdf, font_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b480d7b0-ee4e-4e66-a12a-e44c9b4ee252",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(ratio_cdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6acc1a-1d6e-45c5-a69f-3af90b847982",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(ratio_cdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9439920c-1f60-4150-94ad-7fc7bad07cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(ratio_cdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accb697c-dae4-44a8-b264-7d6639a3c70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(ratio_cdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c61f5c-5df5-41f5-908b-b81fac43ea1f",
   "metadata": {},
   "source": [
    "## Citations\n",
    "\n",
    "```{bibliography}\n",
    ":filter: docname in docnames\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71186c1a-6368-4978-a0a3-48321811552a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f17218-aa35-420e-a9db-2a5360efdcaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
