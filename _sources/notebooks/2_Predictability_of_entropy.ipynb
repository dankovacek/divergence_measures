{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5102c59-e6d1-40c9-8fba-3503a7b34cfa",
   "metadata": {},
   "source": [
    "# Predictability of (Shannon) Entropy\n",
    "\n",
    "In the data preprocessing, we computed the entropy of the distribution of each individual streamflow time series in bits per sample.  We'll now use an ensemble decision tree method called XGBoost (eXtreme Gradient Boosted decision tree) {cite}`chen2016xgboost` to see if the entropy (or uncertainty) of a distribution can be predicted from catchment attributes.  The dictionary size (number of quantization levels) is varied to test if the additional information in the distribution can be exploited by the model.  The model input features are added in successive model tests to compare the contribution of catchment attribute groups related to climate, terrain, land cover, and soil.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b56f760d-4fe7-4a86-bfc4-a9fa56018c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de943461-f460-47b6-8c5b-16f45e07356f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the catchment characteristics\n",
    "fname = 'BCUB_HYSETS_properties_with_climate_with_entropy.csv'\n",
    "df = pd.read_csv(os.path.join('data', fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3f8dcc-d438-474c-876d-77deb64a2b8f",
   "metadata": {},
   "source": [
    "Subdivide the attributes into related classes: terrain, land cover, soil, climate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a86bb960-99c4-48b2-832a-0b3f233d0c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['official_id', 'watershed_id', 'name', 'centroid_lat_deg_n', 'centroid_lon_deg_e', 'drainage_area_km2', 'drainage_area_gsim_km2', 'flag_gsim_boundaries', 'flag_artificial_boundaries', 'elevation_m', 'slope_deg', 'gravelius', 'perimeter', 'flag_shape_extraction', 'aspect_deg', 'flag_terrain_extraction', 'land_use_forest_frac_2010', 'land_use_grass_frac_2010', 'land_use_wetland_frac_2010', 'land_use_water_frac_2010', 'land_use_urban_frac_2010', 'land_use_shrubs_frac_2010', 'land_use_crops_frac_2010', 'land_use_snow_ice_frac_2010', 'flag_land_use_extraction', 'logk_ice_x100', 'porosity_x100', 'flag_subsoil_extraction', 'year_from', 'year_to', 'record_length', 'agency', 'status', 'updated_official_basin', 'in_bcub', 'prcp', 'srad', 'swe', 'tmax', 'tmin', 'vp', 'high_prcp_freq', 'high_prcp_duration', 'low_prcp_freq', 'low_prcp_duration', 'H_4_bits', 'H_6_bits', 'H_8_bits']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "407c1113-81ed-4428-a448-8b7f2bd771c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "terrain = ['drainage_area_km2', 'elevation_m', 'slope_deg', 'gravelius', 'perimeter', 'aspect_deg']\n",
    "land_cover = [\n",
    "    'land_use_forest_frac_2010', 'land_use_grass_frac_2010', 'land_use_wetland_frac_2010', 'land_use_water_frac_2010', \n",
    "    'land_use_urban_frac_2010', 'land_use_shrubs_frac_2010', 'land_use_crops_frac_2010', 'land_use_snow_ice_frac_2010']\n",
    "soil = ['logk_ice_x100', 'porosity_x100']\n",
    "climate = ['prcp', 'srad', 'swe', 'tmax', 'tmin', 'vp', 'high_prcp_freq', 'high_prcp_duration', 'low_prcp_freq', 'low_prcp_duration']\n",
    "all_attributes = terrain + land_cover + soil + climate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc46d5fc-1eff-4cfa-94bb-3ed0710810ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(input_data, target_column, holdout_pct):\n",
    "    n_holdout = int(holdout_pct * len(input_data))\n",
    "    excluded_set = np.random.choice(input_data.index.values, holdout, replace=False)\n",
    "    feature_columns = [c for c in input_data.columns if c != target_column]\n",
    "    X_train = input_data.loc[~input_data.index.isin(excluded_idxs), feature_columns].copy().values\n",
    "    Y_train = input_data.loc[~input_data.index.isin(excluded_idxs), target_column].copy().values\n",
    "    X_test = input_data.loc[input_data.index.isin(excluded_idxs), feature_columns].copy().values\n",
    "    Y_test = input_data.loc[input_data.index.isin(excluded_idxs), target_column].copy().values\n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515fcf0d-048d-4e27-b65a-3c181b198100",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class XGBInstance:\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        cv_param,\n",
    "        bitrate,\n",
    "        feature_columns,\n",
    "        loss,\n",
    "        concurrent_data,\n",
    "        test_dir,\n",
    "        target_column,\n",
    "        n_simulations,\n",
    "    ):\n",
    "        self.input_df = df\n",
    "        self.bitrate = bitrate\n",
    "        self.loss = loss\n",
    "        self.target_column = target_column\n",
    "        self.features = feature_columns\n",
    "        self.stations = pd.unique(df[[\"proxy\", \"target\"]].values.ravel(\"K\"))\n",
    "        self.cv_param = cv_param\n",
    "        self.K = 100  # final leave out test set\n",
    "        self.max_dist = 1000  # km\n",
    "        self.n_simulations = n_simulations\n",
    "        self.feature_scores = []\n",
    "        self.concurrent_data = concurrent_data\n",
    "        self.test_dir = test_dir\n",
    "        \n",
    "\n",
    "    def create_feature_diff_cols(self):\n",
    "        features = list(set([\"_\".join(e.split(\"_\")[1:]) for e in self.features]))\n",
    "        features = [f for f in features if f != \"distance\"]\n",
    "\n",
    "        for c in features:\n",
    "            self.input_df[f\"{c}_diff\"] = (\n",
    "                self.input_df[f\"proxy_{c}\"] - self.input_df[f\"target_{c}\"]\n",
    "            )\n",
    "\n",
    "    def pairwise_leave_out_at_random(self):\n",
    "        \"\"\"\n",
    "        Leave out K stations at random from the training data.\n",
    "        \"\"\"\n",
    "        excluded_station_ids = np.random.choice(self.stations, self.K, replace=False)\n",
    "\n",
    "        test_mask = self.input_df.apply(\n",
    "            lambda row: row[\"proxy\"] in excluded_station_ids\n",
    "            and row[\"target\"] in excluded_station_ids,\n",
    "            axis=1,\n",
    "        )\n",
    "        train_mask = self.input_df.apply(\n",
    "            lambda row: row[\"proxy\"] not in excluded_station_ids\n",
    "            and row[\"target\"] not in excluded_station_ids,\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "        # split the data into training and test sets\n",
    "        train_df = self.input_df[train_mask].copy().reset_index(drop=True)\n",
    "        test_df = self.input_df[test_mask].copy().reset_index(drop=True)\n",
    "\n",
    "        train_stations_unique = list(\n",
    "            set(train_df[[\"proxy\", \"target\"]].values.flatten())\n",
    "        )\n",
    "        test_stations_unique = list(set(test_df[[\"proxy\", \"target\"]].values.flatten()))\n",
    "        # assert that the training and test sets are mutually exclusive\n",
    "        assert len(np.intersect1d(train_stations_unique, test_stations_unique)) == 0\n",
    "        print(\n",
    "            f\"    {len(train_stations_unique)} unique stations in training set, {len(test_stations_unique)} in test set.\"\n",
    "        )\n",
    "        return train_df, test_df\n",
    "\n",
    "    def filter_training_data(self):\n",
    "        self.input_df = self.input_df[\n",
    "            self.input_df[\"centroid_distance\"] <= self.max_dist\n",
    "        ]\n",
    "        train_df, test_df = self.pairwise_leave_out_at_random()\n",
    "        return train_df, test_df\n",
    "\n",
    "    def prepare_input_data(self):\n",
    "        \"\"\"\n",
    "        First, create a hold-out test set by leaving out K stations at random.\n",
    "        Then format the train and test data for the model inputs.\n",
    "        \"\"\"\n",
    "        # Split the data into features and target\n",
    "        self.X_train_filtered, self.X_test_filtered = self.filter_training_data()\n",
    "\n",
    "        X_train = self.X_train_filtered[self.features].values\n",
    "        X_test = self.X_test_filtered[self.features].values\n",
    "\n",
    "        Y_train = self.X_train_filtered[self.target_column].values\n",
    "        Y_test = self.X_test_filtered[self.target_column].values\n",
    "\n",
    "        return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "    def save_feature_importance_plot(self):\n",
    "\n",
    "        # Sort the feature importances\n",
    "        feature_importances = self.model.get_booster().get_score(\n",
    "            importance_type=\"weight\"\n",
    "        )\n",
    "\n",
    "        sorted_importances = sorted(\n",
    "            feature_importances.items(), key=lambda x: x[1], reverse=True\n",
    "        )\n",
    "\n",
    "        # Unpack the labels and values\n",
    "        labels, values = zip(*sorted_importances)\n",
    "\n",
    "        # get the corresponding feature names\n",
    "        self.feature_labels = [self.features[int(e.split(\"f\")[1])] for e in labels]\n",
    "        self.feaure_score_dict = {k: v for k, v in zip(self.feature_labels, values)}\n",
    "        self.feature_scores.append(self.feaure_score_dict)\n",
    "        fs_df = pd.DataFrame(self.feature_scores).T\n",
    "\n",
    "        # return fs_df\n",
    "        # Create the plot\n",
    "        # fig, ax = plt.subplots()\n",
    "        # ax.barh(self.feature_labels, values)\n",
    "        # ax.set_xlabel('Importance')\n",
    "        # ax.set_title('Feature Importance')\n",
    "\n",
    "        # Save the plot as a PNG file\n",
    "        # fig_dir = os.path.join(BASE_DIR, 'processed_data', 'feature_importance_figs')\n",
    "        # plt.gcf().set_size_inches(8, 12)\n",
    "        # plt.savefig(os.path.join(fig_dir,\n",
    "        #             f'{self.model_id}.png'),\n",
    "        # bbox_inches='tight')\n",
    "\n",
    "        # Close the plot to avoid displaying it\n",
    "        # plt.close()\n",
    "        return fs_df\n",
    "\n",
    "    def __call__(self, trial):\n",
    "\n",
    "        # Define hyperparameter space\n",
    "        # max_depth = trial.suggest_int(\"max_depth\", 2, 6)\n",
    "        learning_rate = trial.suggest_float(\"learning_rate\", 0.04, 0.25)\n",
    "        # reg_alpha = trial.suggest_float(\"reg_alpha\", 1.0, 1.2)  # L1 reg\n",
    "        # reg_lambda = trial.suggest_float(\"reg_lambda\", 0.9, 1.0, log=True)  # L2 reg\n",
    "        subsample = trial.suggest_float(\"subsamples\", 0.6, 0.85)\n",
    "        colsample = trial.suggest_float(\"colsample_bytree\", 0.6, 0.85)\n",
    "\n",
    "        params = {\n",
    "            \"objective\": \"binary:logistic\",\n",
    "            \"eval_metric\": \"auc\",\n",
    "            \"eta\": learning_rate,\n",
    "            \"max_depth\": 6,\n",
    "            \"min_child_weight\": 1,\n",
    "            \"subsample\": subsample,\n",
    "            \"colsample_bytree\": colsample,\n",
    "            \"seed\": 42,\n",
    "            \"device\": \"cuda\",\n",
    "        }\n",
    "        self.common_params = params\n",
    "        prior = self.target_column.lower().split(\"_\")[-1].split(\"r\")[0]\n",
    "\n",
    "        # formulate a unique model id using the model parameters\n",
    "        model_id = f\"xgb_{self.bitrate}_b_{prior}_p_{len(self.features)}_features_{concurrent_data}\"\n",
    "        for k, v in self.common_params.items():\n",
    "            if k in [\n",
    "                \"loss\",\n",
    "                \"max_features\",\n",
    "                \"tree_method\",\n",
    "                \"random_state\",\n",
    "                \"eval_metric\",\n",
    "                \"device\",\n",
    "            ]:\n",
    "                continue\n",
    "            if v == \"binary:logistic\":\n",
    "                v = \"logistic\"\n",
    "                self.loss_code = \"auc\"\n",
    "            if isinstance(v, float):\n",
    "                v = f\"{v:1.3e}\"\n",
    "            model_id += f\"_{k}_{v}\"\n",
    "\n",
    "        self.model_id = model_id\n",
    "        mean_error, stdev_error = self.run_model()\n",
    "        return mean_error\n",
    "\n",
    "    def run_model(self):\n",
    "        \"\"\"\n",
    "        1. Train-test split: Randomly select 5% of stations to create final hold-out test set.\n",
    "        2. Model Fit: Fit the model on pairs from the remaining training set.\n",
    "        3. Cross Validation: Evaluate the model with 5-fold cross validation.\n",
    "        4. Stability test: Repeat steps 1-3 ten times holding xgboost hyperparameters constant.\n",
    "        5. Hyperparameter search: Repeat steps 1-4 five times with different hyperparameters.\n",
    "        \"\"\"\n",
    "        model_save_folder = os.path.join(\n",
    "            self.project_dir, \"xgb_models\", self.concurrent_data\n",
    "        )\n",
    "        results_save_folder = os.path.join(\n",
    "            self.project_dir, \"xgb_results\", self.concurrent_data\n",
    "        )\n",
    "        for folder in [results_save_folder, model_save_folder]:\n",
    "            if not os.path.exists(folder):\n",
    "                os.makedirs(folder)\n",
    "\n",
    "        simulation_test_metrics = []\n",
    "        for n in range(self.n_simulations):\n",
    "            model_fname = f\"{n}_{self.model_id}_{self.concurrent_data}.json\"\n",
    "            results_fpath = os.path.join(\n",
    "                results_save_folder, model_fname.replace(\".json\", \".csv\")\n",
    "            )\n",
    "            model_fpath = os.path.join(model_save_folder, model_fname)\n",
    "            if os.path.exists(results_fpath):\n",
    "                print(f\"    Model {n} already exists, skipping.\")\n",
    "                continue\n",
    "            t0 = time()\n",
    "            X_train, Y_train, X_test, Y_test = self.prepare_input_data()\n",
    "\n",
    "            dtrain = xgb.DMatrix(X_train, label=Y_train)\n",
    "\n",
    "            # train the model and do cross validation\n",
    "            self.cv_results = xgb.cv(\n",
    "                params=self.common_params,\n",
    "                dtrain=dtrain,\n",
    "                num_boost_round=2000,\n",
    "                nfold=self.cv_param,\n",
    "                stratified=True,\n",
    "                metrics=\"auc\",\n",
    "                early_stopping_rounds=10,\n",
    "                as_pandas=True,\n",
    "                seed=42,\n",
    "                verbose_eval=False,\n",
    "            )\n",
    "\n",
    "            # Get the optimal number of boosting rounds\n",
    "            optimal_num_boost_round = self.cv_results[f\"test-auc-mean\"].idxmax()\n",
    "            print(f\"    Optimal number of boosting rounds: {optimal_num_boost_round}\")\n",
    "\n",
    "            # train a final model with the optimal number of boosting\n",
    "            # rounds and identical parameters\n",
    "            self.final_model = xgb.XGBClassifier(\n",
    "                n_estimators=optimal_num_boost_round,\n",
    "                learning_rate=self.common_params[\"eta\"],\n",
    "                max_depth=self.common_params[\"max_depth\"],\n",
    "                min_child_weight=self.common_params[\"min_child_weight\"],\n",
    "                subsample=self.common_params[\"subsample\"],\n",
    "                colsample_bytree=self.common_params[\"colsample_bytree\"],\n",
    "                seed=self.common_params[\"seed\"],\n",
    "                use_label_encoder=False,  # Set to False to comply with scikit-learn standards\n",
    "            )\n",
    "            self.final_model.fit(X_train, Y_train)\n",
    "\n",
    "            # Predict probabilities on the held-out test set\n",
    "            y_test_pred_prob = self.final_model.predict(X_test)\n",
    "\n",
    "            # Calculate the AUC on the test set\n",
    "            auc = roc_auc_score(Y_test, y_test_pred_prob)\n",
    "            ascore = accuracy_score(Y_test, y_test_pred_prob)\n",
    "            print(f\"AUC on the test set: {auc:.3f}, accuracy score = {ascore:.2f}\")\n",
    "\n",
    "            self.final_model.save_model(model_fpath)\n",
    "\n",
    "            # evaluate the model on held out test data\n",
    "            # try using the pred_contribs=True to get the feature importance\n",
    "            res_df = pd.DataFrame(\n",
    "                {\n",
    "                    \"actual\": Y_test,\n",
    "                    \"predicted_prob\": y_test_pred_prob,\n",
    "                    \"proxy\": self.X_test_filtered[\"proxy\"].values,\n",
    "                    \"target\": self.X_test_filtered[\"target\"].values,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            res_df.to_csv(os.path.join(results_save_folder, results_fpath), index=False)\n",
    "            simulation_test_metrics.append(auc)\n",
    "\n",
    "        t5 = time()\n",
    "        mean_metric = np.mean(simulation_test_metrics)\n",
    "        stdev_metric = np.std(simulation_test_metrics)\n",
    "\n",
    "        print(\n",
    "            f\"    Completed {self.n_simulations} simulations in {t5 - t0:.2f} seconds\"\n",
    "        )\n",
    "        print(f\"        -mean auc: {mean_metric:.2f} Â± {stdev_metric:.3f}\")\n",
    "        print(\" \")\n",
    "        return mean_metric, stdev_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1a16f7-84df-4e42-9acf-b2a990b30812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the amount of data to set aside for final testing\n",
    "holdout_pct = 0.05\n",
    "\n",
    "for bitrate in [4, 6, 8]:\n",
    "    # set the target column\n",
    "    target_column = f'H_{bitrate}_bits'\n",
    "    test_attributes = []\n",
    "    # add attribute groups successively\n",
    "    for attribute_set in [climate, terrain, land_cover, soil]:\n",
    "        test_attributes += attribute_set\n",
    "        \n",
    "        input_data = df[test_attributes + [target_column]].copy()\n",
    "        \n",
    "        # reset the index to ensure the random selection is done properly\n",
    "        input_data.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # randomly select 5% of the stations to leave out for a hold-out test set\n",
    "        # to ensure none of the data are seen in training\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(input_data, target_column, holdout_pct)\n",
    "        params = {\n",
    "            \"objective\": \"binary:logistic\",\n",
    "            \"eval_metric\": \"auc\",\n",
    "            \"eta\": learning_rate,\n",
    "            \"max_depth\": 6,\n",
    "            \"min_child_weight\": 1,\n",
    "            \"subsample\": subsample,\n",
    "            \"colsample_bytree\": colsample,\n",
    "            \"seed\": 42,\n",
    "            \"device\": \"cuda\",\n",
    "        }\n",
    "        xgb_model = \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e31877-0344-4876-8427-48ea26e5b117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "726a1db2-7b71-45e5-859b-fc3cbd7f0a87",
   "metadata": {},
   "source": [
    "## Citations\n",
    "\n",
    "```{bibliography}\n",
    ":filter: docname in docnames\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
